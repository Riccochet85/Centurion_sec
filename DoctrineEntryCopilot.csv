ListSchema={"schemaXmlList":["<Field ID=\"{fa564e0f-0c70-4ab9-b863-0177e6ddd247}\" Type=\"Text\" Name=\"Title\" DisplayName=\"Title\" Required=\"FALSE\" SourceID=\"http://schemas.microsoft.com/sharepoint/v3\" StaticName=\"Title\" FromBaseType=\"TRUE\" MaxLength=\"255\" />","<Field DisplayName=\"Category\" Format=\"Dropdown\" IsModern=\"TRUE\" MaxLength=\"255\" Name=\"Category\" Title=\"Category\" Type=\"Text\" ID=\"{c4198e10-2e80-416e-a29b-6f55bf6ea17a}\" StaticName=\"Category\" />","<Field ClientSideComponentId=\"00000000-0000-0000-0000-000000000000\" DisplayName=\"Criticality\" Format=\"Dropdown\" MaxLength=\"255\" Name=\"Criticality\" Title=\"Criticality\" Type=\"Text\" ID=\"{3e5fc688-8375-4c14-bffe-13904912359f}\" StaticName=\"Criticality\"><Default>Low</Default></Field>","<Field ClientSideComponentId=\"00000000-0000-0000-0000-000000000000\" DisplayName=\"Version.\" Format=\"Dropdown\" MaxLength=\"255\" Name=\"Version_x002e_\" Title=\"Version.\" Type=\"Text\" ID=\"{2d050711-7f43-48ad-b327-f35dbb02890f}\" StaticName=\"Version_x002e_\"><Default>V1</Default></Field>","<Field DisplayName=\" Tags\" Format=\"Dropdown\" IsModern=\"TRUE\" MaxLength=\"255\" Name=\"Tags\" Title=\" Tags\" Type=\"Text\" ID=\"{a0a8cd03-005c-483d-8e99-b3a20102fdbc}\" StaticName=\"Tags\" />","<Field AppendOnly=\"FALSE\" DisplayName=\"Content\" Format=\"Dropdown\" IsModern=\"TRUE\" IsolateStyles=\"FALSE\" Name=\"Content\" RichText=\"FALSE\" RichTextMode=\"Compatible\" Title=\"Content\" Type=\"Note\" ID=\"{0c0b78bf-a73e-40d4-acda-039302d9e83f}\" StaticName=\"Content\" />","<Field ID=\"{82642ec8-ef9b-478f-acf9-31f7d45fbc31}\" DisplayName=\"Title\" Description=\"\" Name=\"LinkTitle\" SourceID=\"http://schemas.microsoft.com/sharepoint/v3\" StaticName=\"LinkTitle\" Type=\"Computed\" ReadOnly=\"TRUE\" FromBaseType=\"TRUE\" Width=\"150\" DisplayNameSrcField=\"Title\" Sealed=\"FALSE\"><FieldRefs><FieldRef Name=\"Title\" /><FieldRef Name=\"LinkTitleNoMenu\" /><FieldRef Name=\"_EditMenuTableStart2\" /><FieldRef Name=\"_EditMenuTableEnd\" /></FieldRefs><DisplayPattern><FieldSwitch><Expr><GetVar Name=\"FreeForm\" /></Expr><Case Value=\"TRUE\"><Field Name=\"LinkTitleNoMenu\" /></Case><Default><HTML><![CDATA[<div class=\"ms-vb itx\" onmouseover=\"OnItem(this)\" CTXName=\"ctx]]></HTML><Field Name=\"_EditMenuTableStart2\" /><HTML><![CDATA[\">]]></HTML><Field Name=\"LinkTitleNoMenu\" /><HTML><![CDATA[</div>]]></HTML><HTML><![CDATA[<div class=\"s4-ctx\" onmouseover=\"OnChildItem(this.parentNode); return false;\">]]></HTML><HTML><![CDATA[<span>&nbsp;</span>]]></HTML><HTML><![CDATA[<a onfocus=\"OnChildItem(this.parentNode.parentNode); return false;\" onclick=\"PopMenuFromChevron(event); return false;\" href=\"javascript:;\" title=\"Open Menu\"></a>]]></HTML><HTML><![CDATA[<span>&nbsp;</span>]]></HTML><HTML><![CDATA[</div>]]></HTML></Default></FieldSwitch></DisplayPattern></Field>"]}
"Title","Category","Criticality","Version."," Tags","Content"
"Deep_CleanScript_DevToolsConsole.js","Script","VERY LOW","V1","web browser,JavaScript,","// Clear cookies (requires secure context)
document.cookie.split("";"").forEach(c => {
  document.cookie = c
    .replace(/^ +/, """")
    .replace(/=.*/, ""=;expires=Thu, 01 Jan 1970 00:00:00 UTC;path=/"");
});

// Clear local/session storage
localStorage.clear();
sessionStorage.clear();

// Clear all caches (Service Workers)
if ('caches' in window) {
  caches.keys().then(keys => keys.forEach(k => caches.delete(k)));
}

console.log(""All browser storage cleared."");"
"Deep_CleanScript_DevToolsConsole.js","Script","VERY LOW","V3","web browser,JavaScript, cookies","// Clear all cookies
document.cookie.split("";"").forEach(c => {
  document.cookie = c
    .replace(/^ +/, """")
    .replace(/=.*/, ""=;expires=Thu, 01 Jan 1970 00:00:00 UTC;path=/"");
});

// Clear localStorage & sessionStorage
localStorage.clear();
sessionStorage.clear();

// Clear all Service Worker caches
if (""caches"" in window) {
  caches.keys().then(keys => keys.forEach(k => caches.delete(k)));
}

// Unregister all Service Workers
if (""serviceWorker"" in navigator) {
  navigator.serviceWorker.getRegistrations().then(regs => {
    regs.forEach(reg => reg.unregister());
  });
}

console.log(""Deep clean complete."");"
"Deep_CleanScript_DevToolsConsole.js","Script","VERY LOW","V2","web browser,JavaScript, cookies","// // Cookies
document.cookie.split("";"").forEach(c =>
  document.cookie = c.replace(/^ +/, """")
    .replace(/=.*/, ""=;expires=Thu, 01 Jan 1970 00:00:00 UTC;path=/"")
);

// Storage
localStorage.clear();
sessionStorage.clear();

// IndexedDB (browser temp-like data)
indexedDB.databases().then(dbs =>
  dbs.forEach(db => indexedDB.deleteDatabase(db.name))
);

// Cache Storage
if (window.caches)
  caches.keys().then(keys => keys.forEach(k => caches.delete(k)));

// Service Workers
if (navigator.serviceWorker)
  navigator.serviceWorker.getRegistrations()
    .then(regs => regs.forEach(r => r.unregister()));

console.log(""Deep clean complete (cookies, storage, IndexedDB, caches, SW)."");"
"Task_Schedule_trigger","Command line","Low","V1","Windows, PowerShell, task_scheduled,Trigger","# Create a daily task at 8:00 AM
$action = New-ScheduledTaskAction -Execute ""notepad.exe""
$trigger = New-ScheduledTaskTrigger -Daily -At 8:00AM
Register-ScheduledTask -Action $action -Trigger $trigger -TaskName ""OpenNotepadDaily"""
"Task_Schedule_trigger_py","module","Low","V1","Python, Task_scheduled ","def my_task():
    print(""Task executed"")

# Repeat every 10 seconds
while True:
    my_task()
    time.sleep(10)"
"Task_Schedule_trigger_js","Command line","Low","V1","Javascript","
function myTask() {
    console.log(""Task executed"");
}

// Repeat every 5 seconds
setInterval(myTask, 5000);"
"Task_Schedule_trigger_Mandatory_parametres_valid_time","Command line","Low","V1",,"param (
    [Parameter(Mandatory = $true)]
    [ValidateScript({ Test-Path $_ })] # Must be a valid file path
    [string]$ScriptPath,

    [Parameter(Mandatory = $true)]
    [ValidateNotNullOrEmpty()]
    [string]$TaskName,

    [Parameter(Mandatory = $true)]
    [ValidatePattern('^\d{2}:\d{2}$')] # Must match hh:mm
    [string]$RepeatInterval
)

Write-Host ""Validated Script Path: $ScriptPath""
Write-Host ""Validated Task Name: $TaskName""
Write-Host ""Validated Repeat Interval: $RepeatInterval"""
"Task_Schedule_trigger_Mandatory_parameters","Command line","Low","V1",,"param (
    # Script path parameter (must be provided)
    [Parameter(Mandatory = $true)]
    [string]$ScriptPath,

    # Task name parameter (must be provided)
    [Parameter(Mandatory = $true)]
    [string]$TaskName,

    # Repeat interval parameter (must be provided, format hh:mm)
    [Parameter(Mandatory = $true)]
    [string]$RepeatInterval
)

# Example output
Write-Host ""Script Path: $ScriptPath""
Write-Host ""Task Name: $TaskName""
Write-Host ""Repeat Interval: $RepeatInterval"
"Task_Schedule_trigger_default_parameters","Command line","Low","V1",,"param (
    [Parameter(Mandatory = $false)]
    [string]$ScriptPath = ""C:\Path\To\DefaultScript.ps1"",

    [Parameter(Mandatory = $false)]
    [string]$TaskName = ""DefaultTaskName"",

    [Parameter(Mandatory = $false)]
    [string]$RepeatInterval = ""01:00""
)

Write-Host ""Script Path: $ScriptPath""
Write-Host ""Task Name: $TaskName""
Write-Host ""Repeat Interval: $RepeatInterval"""
"Run_Schedule_task_script","Command line ","Low","V1","PowerShell,Command,Run_script","schtasks /create /tn ""Camo Service Watchdog"" /sc onlogon /ru SYSTEM /tr ""powershell.exe -ExecutionPolicy Bypass -File C:\Scripts\CamoServiceWatch.ps1"""
"Copy-Item","Command line ","Low","V1","PowerShell,Command,Copy","Copy-Item -Path ""C:\Users\herbe\OneDrive\Videos\Corn\CORN\Youngtwink"" -Destination ""F:\PH\twinks"" -Recurse -Force"
"Deep_CleanScript_DevToolsConsole.js","JavaScript ","Med","V4","JavaScript.,Console_tool,Browser,cookies ","(async () => {
  const report = {
    timestamp: new Date().toISOString(),
    cookies: {
      before: [],
      after: [],
      attemptedDeletedNames: [],
      deletionSucceeded: null
    },
    storage: {
      localStorage: {
        beforeKeys: [],
        afterKeys: [],
        clearSucceeded: null
      },
      sessionStorage: {
        beforeKeys: [],
        afterKeys: [],
        clearSucceeded: null
      }
    },
    caches: {
      supported: ""caches"" in window,
      keysBefore: [],
      deleteResults: [],
      keysAfter: null,
      allDeleted: null,
      error: null
    },
    serviceWorkers: {
      supported: ""serviceWorker"" in navigator,
      countBefore: null,
      unregisterResults: [],
      countAfter: null,
      allUnregistered: null,
      error: null
    }
  };

  // -----------------------------
  // 1. COOKIES
  // -----------------------------
  const rawBeforeCookies = document.cookie ? document.cookie.split("";"") : [];
  report.cookies.before = rawBeforeCookies.map(c => c.trim());

  report.cookies.before.forEach(c => {
    const name = c.split(""="")[0];
    report.cookies.attemptedDeletedNames.push(name);
    document.cookie = `${name}=;expires=Thu, 01 Jan 1970 00:00:00 GMT;path=/`;
  });

  const rawAfterCookies = document.cookie ? document.cookie.split("";"") : [];
  report.cookies.after = rawAfterCookies
    .map(c => c.trim())
    .filter(c => c !== """");
  report.cookies.deletionSucceeded = report.cookies.after.length === 0;

  // -----------------------------
  // 2. STORAGE
  // -----------------------------
  // localStorage
  try {
    report.storage.localStorage.beforeKeys = Object.keys(localStorage);
    localStorage.clear();
    report.storage.localStorage.afterKeys = Object.keys(localStorage);
    report.storage.localStorage.clearSucceeded =
      report.storage.localStorage.afterKeys.length === 0;
  } catch (e) {
    report.storage.localStorage.clearSucceeded = false;
    report.storage.localStorage.error = String(e);
  }

  // sessionStorage
  try {
    report.storage.sessionStorage.beforeKeys = Object.keys(sessionStorage);
    sessionStorage.clear();
    report.storage.sessionStorage.afterKeys = Object.keys(sessionStorage);
    report.storage.sessionStorage.clearSucceeded =
      report.storage.sessionStorage.afterKeys.length === 0;
  } catch (e) {
    report.storage.sessionStorage.clearSucceeded = false;
    report.storage.sessionStorage.error = String(e);
  }

  // -----------------------------
  // 3. CACHE STORAGE
  // -----------------------------
  if (report.caches.supported) {
    try {
      const keysBefore = await caches.keys();
      report.caches.keysBefore = keysBefore.slice();

      const deleteResults = [];
      for (const key of keysBefore) {
        const res = await caches.delete(key);
        deleteResults.push({ key, deleted: res });
      }
      report.caches.deleteResults = deleteResults;

      const keysAfter = await caches.keys();
      report.caches.keysAfter = keysAfter.slice();
      report.caches.allDeleted = keysAfter.length === 0;
    } catch (e) {
      report.caches.error = String(e);
      report.caches.allDeleted = false;
    }
  }

  // -----------------------------
  // 4. SERVICE WORKERS
  // -----------------------------
  if (report.serviceWorkers.supported) {
    try {
      const regsBefore = await navigator.serviceWorker.getRegistrations();
      report.serviceWorkers.countBefore = regsBefore.length;

      const unregisterResults = [];
      for (const reg of regsBefore) {
        const res = await reg.unregister();
        unregisterResults.push({ scope: reg.scope, unregistered: res });
      }
      report.serviceWorkers.unregisterResults = unregisterResults;

      const regsAfter = await navigator.serviceWorker.getRegistrations();
      report.serviceWorkers.countAfter = regsAfter.length;
      report.serviceWorkers.allUnregistered =
        regsAfter.length === 0 &&
        unregisterResults.every(r => r.unregistered === true);
    } catch (e) {
      report.serviceWorkers.error = String(e);
      report.serviceWorkers.allUnregistered = false;
    }
  }

  // -----------------------------
  // 5. FINAL STRUCTURED REPORT
  // -----------------------------
  report.summary = {
    cookiesDeleted:
      report.cookies.before.length > 0 && report.cookies.deletionSucceeded,
    cookiesRemaining: report.cookies.after.length,
    localStorageCleared: report.storage.localStorage.clearSucceeded,
    sessionStorageCleared: report.storage.sessionStorage.clearSucceeded,
    cachesAllDeleted:
      report.caches.supported ? report.caches.allDeleted : null,
    serviceWorkersAllUnregistered:
      report.serviceWorkers.supported
        ? report.serviceWorkers.allUnregistered
        : null
  };

  // Single structured, truthful report
  console.log(report);
})();
"
"Get-DnsClientServerAddress","DnsClient_Module","High","V1","Default,Get,DnsClient,Windows","Get-DnsClientServerAddress
    [-InterfaceIndex <UInt32[]>]
    [[-InterfaceAlias] <String[]>]
    [-AddressFamily <AddressFamily[]>]
    [-CimSession <CimSession[]>]
    [-ThrottleLimit <Int32>]
    [-AsJob]
    [<CommonParameters>]"
"DnsClient_Module_docs","Documentation","High","V1","Documentation,Windows","Description
The Get-DnsClientServerAddress cmdlet gets one or more DNS server IP addresses associated with the interfaces on the computer.

Examples
Example 1: Get DNS server IP addresses for all interfaces
PS C:\> Get-DnsClientServerAddress
This example gets the DNS server IP addresses configured on all the interfaces on a computer.

Example 2: Get DNS server IP addresses for a specified interface
PS C:\> Get-DnsClientServerAddress -InterfaceAlias ""Wired Ethernet Connection""
This example gets the DNS server IP addresses configured on the interface named Wired Ethernet Connection.

Parameters
-AddressFamily
Specifies the address family. The acceptable values for this parameter are: IPv4 or IPv6.

Parameter properties
Type:	
AddressFamily[]

Default value:	None
Accepted values:	IPv4, IPv6
Supports wildcards:	False
DontShow:	False
Aliases:	Family
Parameter sets
(All) 
Position:	Named
Mandatory:	False
Value from pipeline:	False
Value from pipeline by property name:	False
Value from remaining arguments:	False
-AsJob
Runs the cmdlet as a background job. Use this parameter to run commands that take a long time to complete.

The cmdlet immediately returns an object that represents the job and then displays the command prompt. You can continue to work in the session while the job completes. To manage the job, use the *-Job cmdlets. To get the job results, use the Receive-Job cmdlet.

For more information about Windows PowerShell background jobs, see about_Jobs.

Parameter properties
Type:	SwitchParameter
Default value:	None
Supports wildcards:	False
DontShow:	False
Parameter sets
(All) 
Position:	Named
Mandatory:	False
Value from pipeline:	False
Value from pipeline by property name:	False
Value from remaining arguments:	False
-CimSession
Runs the cmdlet in a remote session or on a remote computer. Enter a computer name or a session object, such as the output of a New-CimSession or Get-CimSession cmdlet. The default is the current session on the local computer.

Parameter properties
Type:	
CimSession[]

Default value:	None
Supports wildcards:	False
DontShow:	False
Aliases:	Session
Parameter sets
(All) 
Position:	Named
Mandatory:	False
Value from pipeline:	False
Value from pipeline by property name:	False
Value from remaining arguments:	False
-InterfaceAlias
Specifies the friendly name of the interface.

Parameter properties
Type:	
String[]

Default value:	None
Supports wildcards:	False
DontShow:	False
Parameter sets
(All) 
Position:	0
Mandatory:	False
Value from pipeline:	False
Value from pipeline by property name:	False
Value from remaining arguments:	False
-InterfaceIndex
Specifies the index number of the interface.

Parameter properties
Type:	
UInt32[]

Default value:	None
Supports wildcards:	False
DontShow:	False
Parameter sets
(All) 
Position:	Named
Mandatory:	False
Value from pipeline:	True
Value from pipeline by property name:	True
Value from remaining arguments:	False
-ThrottleLimit
Specifies the maximum number of concurrent operations that can be established to run the cmdlet. If this parameter is omitted or a value of 0 is entered, then Windows PowerShell® calculates an optimum throttle limit for the cmdlet based on the number of CIM cmdlets that are running on the computer. The throttle limit applies only to the current cmdlet, not to the session or to the computer.

Parameter properties
Type:	Int32
Default value:	None
Supports wildcards:	False
DontShow:	False
Parameter sets
(All) 
Position:	Named
Mandatory:	False
Value from pipeline:	False
Value from pipeline by property name:	False
Value from remaining arguments:	False
CommonParameters
This cmdlet supports the common parameters: -Debug, -ErrorAction, -ErrorVariable, -InformationAction, -InformationVariable, -OutBuffer, -OutVariable, -PipelineVariable, -ProgressAction, -Verbose, -WarningAction, and -WarningVariable. For more information, see about_CommonParameters.

Inputs
None
Outputs
CimInstance
The Microsoft.Management.Infrastructure.CimInstance object is a wrapper class that displays Windows Management Instrumentation (WMI) objects. The path after the pound sign (#) provides the namespace and class name for the underlying WMI object.

CimInstance
The Microsoft.Management.Infrastructure.CimInstance object is a wrapper class that displays Windows Management Instrumentation (WMI) objects. The path after the pound sign (#) provides the namespace and class name for the underlying WMI object.

CimInstance
The Microsoft.Management.Infrastructure.CimInstance object is a wrapper class that displays Windows Management Instrumentation (WMI) objects. The path after the pound sign (#) provides the namespace and class name for the underlying WMI object.

CimInstance
The Microsoft.Management.Infrastructure.CimInstance object is a wrapper class that displays Windows Management Instrumentation (WMI) objects. The path after the pound sign (#) provides the namespace and class name for the underlying WMI object."
"New_ScheduledTask_Module","Dcumentation","High","V1",,"ScheduledTasks Module
In this article
Syntax 
Syntax
Default (Default)
Description
Examples 
Examples
Example 1: Define a scheduled task and register it at a later time
Example 2: Define a scheduled task with multiple actions
Parameters 
Parameters
-Action
-AsJob
-CimSession
-Description
-Principal
-Settings
-ThrottleLimit
-Trigger
CommonParameters
Outputs 
Related Links
Show less
Creates a scheduled task instance.

Syntax
Default (Default)
Syntax
New-ScheduledTask
    [[-Action] <CimInstance[]>]
    [[-Description] <String>]
    [[-Principal] <CimInstance>]
    [[-Settings] <CimInstance>]
    [[-Trigger] <CimInstance[]>]
    [-CimSession <CimSession[]>]
    [-ThrottleLimit <Int32>]
    [-AsJob]
    [<CommonParameters>]
Description
The New-ScheduledTask cmdlet creates an object that contains the definition of a scheduled task. New-ScheduledTask does not automatically register the object with the Task Scheduler service.

You can register a task to run any of the following application or file types: Win32 applications, Win16 applications, OS/2 applications, MS-DOS applications, batch files (.bat), command files (.cmd), or any properly registered file type.

Examples
Example 1: Define a scheduled task and register it at a later time
PowerShell
PS C:\> $action = New-ScheduledTaskAction -Execute ""Taskmgr.exe""
PS C:\> $trigger = New-ScheduledTaskTrigger -AtLogon
PS C:\> $principal = ""Contoso\Administrator""
PS C:\> $settings = New-ScheduledTaskSettingsSet
PS C:\> $task = New-ScheduledTask -Action $action -Principal $principal -Trigger $trigger -Settings $settings
PS C:\> Register-ScheduledTask T1 -InputObject $task
In this example, the set of commands uses several cmdlets and variables to define and then register a scheduled task.

The first command uses the New-ScheduledTaskAction cmdlet to assign the executable file tskmgr.exe to the variable $action.

The second command uses the New-ScheduledTaskTrigger cmdlet to assign the value AtLogon to the variable $trigger.

The third command assigns the principal of the scheduled task Contoso\Administrator to the variable $principal.

The fourth command uses the New-ScheduledTaskSettingsSet cmdlet to assign a task settings object to the variable $settings.

The fifth command creates a new task and assigns the task definition to the variable $task.

The sixth command (hypothetically) runs at a later time. It registers the new scheduled task and defines it by using the $task variable.

Example 2: Define a scheduled task with multiple actions
PowerShell
PS C:\> $actions = (New-ScheduledTaskAction –Execute 'foo.ps1'), (New-ScheduledTaskAction –Execute 'bar.ps1')
PS C:\> $trigger = New-ScheduledTaskTrigger -Daily -At '9:15 AM'
PS C:\> $principal = New-ScheduledTaskPrincipal -UserId 'DOMAIN\user' -RunLevel Highest
PS C:\> $settings = New-ScheduledTaskSettingsSet -RunOnlyIfNetworkAvailable -WakeToRun
PS C:\> $task = New-ScheduledTask -Action $actions -Principal $principal -Trigger $trigger -Settings $settings

PS C:\> Register-ScheduledTask 'baz' -InputObject $task

This example creates and registers a scheduled task that runs two PowerShell scripts daily at 09:15 AM.

Parameters
-Action
Specifies an array of work items for a task to run. When you specify multiple actions, they run sequentially. A task can have up to 32 actions.

Parameter properties
Type:	
CimInstance[]

Default value:	None
Supports wildcards:	False
DontShow:	False
Parameter sets
(All) 
Position:	0
Mandatory:	False
Value from pipeline:	False
Value from pipeline by property name:	False
Value from remaining arguments:	False
-AsJob
Runs the cmdlet as a background job. Use this parameter to run commands that take a long time to complete.

Parameter properties
Type:	SwitchParameter
Default value:	None
Supports wildcards:	False
DontShow:	False
Parameter sets
(All) 
Position:	Named
Mandatory:	False
Value from pipeline:	False
Value from pipeline by property name:	False
Value from remaining arguments:	False
-CimSession
Runs the cmdlet in a remote session or on a remote computer. Enter a computer name or a session object, such as the output of a New-CimSession or Get-CimSession cmdlet. The default is the current session on the local computer.

Parameter properties
Type:	
CimSession[]

Default value:	None
Supports wildcards:	False
DontShow:	False
Aliases:	Session
Parameter sets
(All) 
Position:	Named
Mandatory:	False
Value from pipeline:	False
Value from pipeline by property name:	False
Value from remaining arguments:	False
-Description
Briefly describes the task.

Parameter properties
Type:	String
Default value:	None
Supports wildcards:	False
DontShow:	False
Parameter sets
(All) 
Position:	4
Mandatory:	False
Value from pipeline:	False
Value from pipeline by property name:	False
Value from remaining arguments:	False
-Principal
Specifies the security context in which a task runs.

Parameter properties
Type:	CimInstance
Default value:	None
Supports wildcards:	False
DontShow:	False
Parameter sets
(All) 
Position:	3
Mandatory:	False
Value from pipeline:	False
Value from pipeline by property name:	False
Value from remaining arguments:	False
-Settings
Specifies a configuration object that the Task Scheduler service uses to determine how to run a task.

Parameter properties
Type:	CimInstance
Default value:	None
Supports wildcards:	False
DontShow:	False
Parameter sets
(All) 
Position:	2
Mandatory:	False
Value from pipeline:	False
Value from pipeline by property name:	False
Value from remaining arguments:	False
-ThrottleLimit
Specifies the maximum number of concurrent operations that can be established to run the cmdlet. If this parameter is omitted or a value of 0 is entered, then Windows PowerShell® calculates an optimum throttle limit for the cmdlet based on the number of CIM cmdlets that are running on the computer. The throttle limit applies only to the current cmdlet, not to the session or to the computer.

Parameter properties
Type:	Int32
Default value:	None
Supports wildcards:	False
DontShow:	False
Parameter sets
(All) 
Position:	Named
Mandatory:	False
Value from pipeline:	False
Value from pipeline by property name:	False
Value from remaining arguments:	False
-Trigger
Specifies an array of one or more trigger objects that cause a scheduled task to start.

A trigger is a set of criteria that starts a scheduled task when the criteria are met. You can use a time-based trigger or an event-based trigger to start a task, and one or more triggers can start a task. A task can have up to 48 triggers. For more information about triggers, see Triggers.

Parameter properties
Type:	
CimInstance[]

Default value:	None
Supports wildcards:	False
DontShow:	False
Parameter sets
(All) 
Position:	1
Mandatory:	False
Value from pipeline:	False
Value from pipeline by property name:	False
Value from remaining arguments:	False
CommonParameters
This cmdlet supports the common parameters: -Debug, -ErrorAction, -ErrorVariable, -InformationAction, -InformationVariable, -OutBuffer, -OutVariable, -PipelineVariable, -ProgressAction, -Verbose, -WarningAction, and -WarningVariable. For more information, see about_CommonParameters.

Outputs
CimInstance
"
"Triggers","Documentation","Low","V1",,"Applies To: Windows 7, Windows Server 2008 R2, Windows Server 2012, Windows Vista

When setting up a task, first decide what will trigger that task to start. A trigger is a set of criteria that, when met, starts the execution of a task. A task's triggers are displayed on the Triggers tab of the Task Properties or Create Task dialog box. You can use a time-based trigger or an event-based trigger to start a task. Time-based triggers include starting a task at a specific time of day or starting a task multiple times on a daily, weekly, or monthly schedule. Event-based triggers start a task in response to certain system events. For example, event-based triggers can be set to start a task when the system starts up, when a user logs on to the computer, or when the computer enters an idle state. Each task can contain one or more triggers, allowing the task to be started in many ways. If a task has multiple triggers, the task will start when any of the triggers occur.

Trigger Settings
Each trigger contains settings that determine the criteria to activate the trigger. Additional advanced settings can be set for each trigger, which is explained in the Advanced Settings section below. The trigger settings are accessed from the Edit Trigger or New Trigger dialog box, which is viewed by clicking on the Edit or New button on the Triggers tab in the Task Properties or Create Task dialog box. For more information about how to change trigger settings, see Change an Existing Task or Schedule a Task.

Triggers
The following list describes each trigger and the trigger settings.

On a schedule

This trigger causes the task to run according to a schedule, and the trigger settings allow you to set the schedule. You can choose to schedule the task at one time, or on a daily, weekly, or monthly schedule. The time you set is relative to the time zone that is set on the computer that runs the task. Check the Universal check box to make the time relative to Coordinated Universal Time (UTC) instead of the time zone that is set on the computer that runs the task. Use the Universal setting when you want to coordinate a set of tasks to run simultaneously in multiple time zones.

If you select the One time radio button, you choose a date and time to trigger the task.

If you select the Daily radio button, you choose the recurrence interval for the task and the date and time to start the task. An interval of 1 produces a daily schedule and an interval of 2 produces an every other day schedule. The task will start at the specified time each day.

If you select the Weekly radio button, you choose the recurrence interval for the task, the date and time to start the task, and the days of the week in which to start the task. An interval of 1 produces a weekly schedule and an interval of 2 produces an every other week schedule. The task will start at the specified time on each of the specified days.

If you select the Monthly radio button, you choose the months in which you want to start the task and the weeks of the month and the days of the week for each month in which you want to start the task. You can also specify that you want to start a task on the last day of each month.

At log on

This trigger causes the task to run when a user logs on to the computer, and the trigger's settings allow you to specify that the task should be triggered when any user logs on the computer or when a specific user logs on.

At startup

This trigger causes the task to run when the computer starts up. The only settings for this trigger are the advanced settings described in the Advanced Settings section below.

On idle

This trigger causes the task to run after the computer enters an idle state, and the idle settings can be set from the Conditions tab in the Create Task or Task Properties dialog box. For more information, see Task Conditions.

On an event

This trigger causes the task to run when specific event entries are added to an event log. You can choose between specifying basic event trigger settings or custom event trigger settings. If you choose the basic event trigger settings, a single event from a specific event log will trigger the task. You choose the event log that contains the event, the event publisher name, and specify the event identifier. If you choose the custom event trigger settings, you can specify an XML event query or a custom event filter to query for events that will trigger the task. For more information about event filters, see Create a Custom View.

 Note

This trigger is not available for tasks configured for Windows Server 2003, Windows XP, or Windows 2000.

At task creation/modification

This trigger causes a task to run as soon as it is created and when the task is modified. The only settings for this trigger are the advanced settings described in the Advanced Settings section below.

 Note

This trigger is not available for tasks configured for Windows Server 2003, Windows XP, or Windows 2000.

On connection to user session

This trigger causes a task to run when a user session is connected to from the local computer or from a remote desktop connection. For example, when you connect to a user session on the local computer by switching users on the computer, this trigger will cause the task to run. Another example that can trigger a task to run is when a user connects to a user session by using the Remote Desktop Connection program from a remote computer. The trigger's settings allow you to specify that the task should be triggered when any user connects to a user session or when a specific user connects.

 Note

This trigger is not available for tasks that are configured for Windows Server 2003, Windows XP, or Windows 2000.

On disconnect from user session

This trigger causes a task to run when a user session is disconnected from the local computer or from a remote desktop connection. For example, when you disconnect from a user session on the local computer by switching users on the computer, this trigger will cause the task to run. Another example that can trigger a task to run is when a user disconnects from a user session by using the Remote Desktop Connection program from a remote computer. The trigger's settings allow you to specify that the task should be triggered when any user disconnects from a user session or when a specific user disconnects.

 Note

This trigger is not available for tasks configured for Windows Server 2003, Windows XP, or Windows 2000.

On workstation lock

This trigger causes the task to run when the computer is locked. The trigger's settings allow you to specify that the task should be triggered when any user locks the computer or when a specific user locks the computer.

 Note

This trigger is not available for tasks configured for Windows Server 2003, Windows XP, or Windows 2000.

On workstation unlock

This trigger causes the task to run when the computer is unlocked. The trigger's settings allow you to specify that the task should be triggered when any user locks the computer or when a specific user locks the computer.

 Note

This trigger is not available for tasks configured for Windows Server 2003, Windows XP, or Windows 2000.

Advanced Settings
The following list describes the advanced trigger settings.

Delay task for or Delay task for up to (random delay) : This setting allows you to specify an amount of time to delay the task from running, after the task is triggered. If you are using a time-based trigger ( On a schedule ), then the delay time will be a random time between the time the task is triggered and the time specified in this setting. If a task is scheduled to be triggered at 1:00 pm, and the Delay task for up to (random delay) setting is set to 5 minutes, then the task will run sometime between 1:00 pm and 1:05 pm.

Repeat task every : This setting allows you to set a repetition time interval for the task. The task will run, wait for the time interval specified, and then run again. This cycle will continue until the duration time is met.

Stop any task that runs longer than : This setting allows you to stop long running tasks by setting a time limit on the amount of time the task is allowed to run (execute the action).

Activate : This setting allows you to set a date and time to activate the trigger. Once a trigger is activated, the trigger can cause the task to run. The time is relative to the time zone that is set on the computer that runs the task. Check the Universal check box to make the time relative to Coordinated Universal Time (UTC) instead of the time zone that is set on the computer that runs the task. Use the Universal setting when you want to coordinate a set of tasks to activate simultaneously in multiple time zones.

Expire : This setting allows you to set a date and time for the trigger to expire. When a trigger is expired, it cannot cause the task to run. The time is relative to the time zone that is set on the computer that runs the task. Check the Universal check box to make the time relative to Coordinated Universal Time (UTC) instead of the time zone that is set on the computer that runs the task. Use the Universal setting when you want to coordinate a set of tasks to expire simultaneously in multiple time zones.

Enabled : This setting allows you to enable or disable the task. A task that is enabled can run, and a task that is disabled cannot run until it is enabled."
"Set-DnsClient Module","Documentation ","High","V1",,"DnsClient Module
Sets the interface-specific DNS client configurations on the computer.

Syntax
ByAlias (Default)
Syntax
Set-DnsClient
    [-InterfaceAlias] <String[]>
    [-ConnectionSpecificSuffix <String>]
    [-RegisterThisConnectionsAddress <Boolean>]
    [-UseSuffixWhenRegistering <Boolean>]
    [-ResetConnectionSpecificSuffix]
    [-CimSession <CimSession[]>]
    [-ThrottleLimit <Int32>]
    [-AsJob]
    [-PassThru]
    [-WhatIf]
    [-Confirm]
    [<CommonParameters>]
ByName
Syntax
Set-DnsClient
    -InterfaceIndex <UInt32[]>
    [-ConnectionSpecificSuffix <String>]
    [-RegisterThisConnectionsAddress <Boolean>]
    [-UseSuffixWhenRegistering <Boolean>]
    [-ResetConnectionSpecificSuffix]
    [-CimSession <CimSession[]>]
    [-ThrottleLimit <Int32>]
    [-AsJob]
    [-PassThru]
    [-WhatIf]
    [-Confirm]
    [<CommonParameters>]
InputObject (cdxml)
Syntax
Set-DnsClient
    -InputObject <CimInstance[]>
    [-ConnectionSpecificSuffix <String>]
    [-RegisterThisConnectionsAddress <Boolean>]
    [-UseSuffixWhenRegistering <Boolean>]
    [-ResetConnectionSpecificSuffix]
    [-CimSession <CimSession[]>]
    [-ThrottleLimit <Int32>]
    [-AsJob]
    [-PassThru]
    [-WhatIf]
    [-Confirm]
    [<CommonParameters>]
Description
The Set-DnsClient cmdlet sets the interface-specific DNS client configurations on the computer.

Examples
Example 1: Set the connection-specific suffix
PowerShell
PS C:\> Set-DnsClient -InterfaceIndex 12 -ConnectionSpecificSuffix ""corp.contoso.com""
This example sets the connection-specific suffix on an interface with index 12.

Parameters
-AsJob
Runs the cmdlet as a background job. Use this parameter to run commands that take a long time to complete.

The cmdlet immediately returns an object that represents the job and then displays the command prompt. You can continue to work in the session while the job completes. To manage the job, use the *-Job cmdlets. To get the job results, use the Receive-Job cmdlet.

For more information about Windows PowerShell background jobs, see about_Jobs.

Parameter properties
Type:	SwitchParameter
Default value:	None
Supports wildcards:	False
DontShow:	False
Parameter sets
(All) 
Position:	Named
Mandatory:	False
Value from pipeline:	False
Value from pipeline by property name:	False
Value from remaining arguments:	False
-CimSession
Runs the cmdlet in a remote session or on a remote computer. Enter a computer name or a session object, such as the output of a New-CimSession or Get-CimSession cmdlet. The default is the current session on the local computer.

Parameter properties
Type:	
CimSession[]

Default value:	None
Supports wildcards:	False
DontShow:	False
Aliases:	Session
Parameter sets
(All) 
Position:	Named
Mandatory:	False
Value from pipeline:	False
Value from pipeline by property name:	False
Value from remaining arguments:	False
-Confirm
Prompts you for confirmation before running the cmdlet.

Parameter properties
Type:	SwitchParameter
Default value:	False
Supports wildcards:	False
DontShow:	False
Aliases:	cf
Parameter sets
(All) 
Position:	Named
Mandatory:	False
Value from pipeline:	False
Value from pipeline by property name:	False
Value from remaining arguments:	False
-ConnectionSpecificSuffix
Specifies the connection-specific suffixes to append. This parameter value is a per-connection DNS suffix to append to the computer name to construct a Fully Qualified Domain Name (FQDN). This FQDN is used as the host name for name resolution by the DNS client.

Parameter properties
Type:	String
Default value:	None
Supports wildcards:	False
DontShow:	False
Aliases:	Suffix
Parameter sets
(All) 
Position:	Named
Mandatory:	False
Value from pipeline:	False
Value from pipeline by property name:	False
Value from remaining arguments:	False
-InputObject
Specifies the input to this cmdlet. You can use this parameter, or you can pipe the input to this cmdlet.

Parameter properties
Type:	
CimInstance[]

Default value:	None
Supports wildcards:	False
DontShow:	False
Parameter sets
InputObject (cdxml) 
Position:	Named
Mandatory:	True
Value from pipeline:	True
Value from pipeline by property name:	False
Value from remaining arguments:	False
-InterfaceAlias
Specifies the friendly name of the interface.

Parameter properties
Type:	
String[]

Default value:	None
Supports wildcards:	False
DontShow:	False
Parameter sets
ByAlias 
Position:	0
Mandatory:	True
Value from pipeline:	False
Value from pipeline by property name:	False
Value from remaining arguments:	False
-InterfaceIndex
Specifies the index number of the interface.

Parameter properties
Type:	
UInt32[]

Default value:	None
Supports wildcards:	False
DontShow:	False
Parameter sets
ByName 
Position:	Named
Mandatory:	True
Value from pipeline:	True
Value from pipeline by property name:	True
Value from remaining arguments:	False
-PassThru
Returns an object representing the item with which you are working. By default, this cmdlet does not generate any output.

Parameter properties
Type:	SwitchParameter
Default value:	None
Supports wildcards:	False
DontShow:	False
Parameter sets
(All) 
Position:	Named
Mandatory:	False
Value from pipeline:	False
Value from pipeline by property name:	False
Value from remaining arguments:	False
-RegisterThisConnectionsAddress
Indicates whether the IP address for this connection is to be registered.

Parameter properties
Type:	Boolean
Default value:	None
Supports wildcards:	False
DontShow:	False
Parameter sets
(All) 
Position:	Named
Mandatory:	False
Value from pipeline:	False
Value from pipeline by property name:	False
Value from remaining arguments:	False
-ResetConnectionSpecificSuffix
Resets the connection-specific suffix to the default value.

Parameter properties
Type:	SwitchParameter
Default value:	None
Supports wildcards:	False
DontShow:	False
Aliases:	ResetSuffix
Parameter sets
(All) 
Position:	Named
Mandatory:	False
Value from pipeline:	False
Value from pipeline by property name:	False
Value from remaining arguments:	False
-ThrottleLimit
Specifies the maximum number of concurrent operations that can be established to run the cmdlet. If this parameter is omitted or a value of 0 is entered, then Windows PowerShell® calculates an optimum throttle limit for the cmdlet based on the number of CIM cmdlets that are running on the computer. The throttle limit applies only to the current cmdlet, not to the session or to the computer.

Parameter properties
Type:	Int32
Default value:	None
Supports wildcards:	False
DontShow:	False
Parameter sets
(All) 
Position:	Named
Mandatory:	False
Value from pipeline:	False
Value from pipeline by property name:	False
Value from remaining arguments:	False
-UseSuffixWhenRegistering
Indicates whether this host name and the connection-specific suffix for this connection are to be registered.

Parameter properties
Type:	Boolean
Default value:	None
Supports wildcards:	False
DontShow:	False
Parameter sets
(All) 
Position:	Named
Mandatory:	False
Value from pipeline:	False
Value from pipeline by property name:	False
Value from remaining arguments:	False
-WhatIf
Shows what would happen if the cmdlet runs. The cmdlet is not run.

Parameter properties
Type:	SwitchParameter
Default value:	False
Supports wildcards:	False
DontShow:	False
Aliases:	wi
Parameter sets
(All) 
Position:	Named
Mandatory:	False
Value from pipeline:	False
Value from pipeline by property name:	False
Value from remaining arguments:	False
CommonParameters
This cmdlet supports the common parameters: -Debug, -ErrorAction, -ErrorVariable, -InformationAction, -InformationVariable, -OutBuffer, -OutVariable, -PipelineVariable, -ProgressAction, -Verbose, -WarningAction, and -WarningVariable. For more information, see about_CommonParameters.

Inputs
CimInstance
The Microsoft.Management.Infrastructure.CimInstance object is a wrapper class that displays Windows Management Instrumentation (WMI) objects. The path after the pound sign (#) provides the namespace and class name for the underlying WMI object.

CimInstance
The Microsoft.Management.Infrastructure.CimInstance object is a wrapper class that displays Windows Management Instrumentation (WMI) objects. The path after the pound sign (#) provides the namespace and class name for the underlying WMI object.

CimInstance
The Microsoft.Management.Infrastructure.CimInstance object is a wrapper class that displays Windows Management Instrumentation (WMI) objects. The path after the pound sign (#) provides the namespace and class name for the underlying WMI object.

CimInstance
The Microsoft.Management.Infrastructure.CimInstance object is a wrapper class that displays Windows Management Instrumentation (WMI) objects. The path after the pound sign (#) provides the namespace and class name for the underlying WMI object.

Outputs
CimInstance
The Microsoft.Management.Infrastructure.CimInstance object is a wrapper class that displays Windows Management Instrumentation (WMI) objects. The path after the pound sign (#) provides the namespace and class name for the underlying WMI object."
"FORCE_GLOBAL_DoH_RESET_MANDATORY","Module","High","V1","PowerShell,Firewall,DoH","# HARD RESET all DoH state
Get-DnsClientDohServerAddress -ErrorAction SilentlyContinue |
ForEach-Object {
    Remove-DnsClientDohServerAddress -ServerAddress $_.ServerAddress -ErrorAction SilentlyContinue
}

# Disable Windows auto-DoH behavior
Set-ItemProperty -Path ""HKLM:\SYSTEM\CurrentControlSet\Services\Dnscache\Parameters"" `
    -Name ""EnableAutoDoh"" -Type DWord -Value 0 -Force

Set-ItemProperty -Path ""HKLM:\SYSTEM\CurrentControlSet\Services\Dnscache\Parameters"" `
    -Name ""EnableDoh"" -Type DWord -Value 1 -Force
"
"LOCK_Cloudflare_DoH_POLICY-LEVEL","Module","Priority","V1",,"foreach ($ip in $AllCloudflareServers) {
    Set-DnsClientDohServerAddress `
        -ServerAddress $ip `
        -DohTemplate $CloudflareDohTemplate `
        -AllowFallbackToUdp $false `
        -AutoUpgrade $false `
        -ErrorAction SilentlyContinue
}
"
"python_general_Glossary","Glossary","Med","3.14.2",,"Glossary¶
>>>
The default Python prompt of the interactive shell. Often seen for code examples which can be executed interactively in the interpreter.

...
Can refer to:

The default Python prompt of the interactive shell when entering the code for an indented code block, when within a pair of matching left and right delimiters (parentheses, square brackets, curly braces or triple quotes), or after specifying a decorator.

The three dots form of the Ellipsis object.

abstract base class
Abstract base classes complement duck-typing by providing a way to define interfaces when other techniques like hasattr() would be clumsy or subtly wrong (for example with magic methods). ABCs introduce virtual subclasses, which are classes that don’t inherit from a class but are still recognized by isinstance() and issubclass(); see the abc module documentation. Python comes with many built-in ABCs for data structures (in the collections.abc module), numbers (in the numbers module), streams (in the io module), import finders and loaders (in the importlib.abc module). You can create your own ABCs with the abc module.

annotate function
A function that can be called to retrieve the annotations of an object. This function is accessible as the __annotate__ attribute of functions, classes, and modules. Annotate functions are a subset of evaluate functions.

annotation
A label associated with a variable, a class attribute or a function parameter or return value, used by convention as a type hint.

Annotations of local variables cannot be accessed at runtime, but annotations of global variables, class attributes, and functions can be retrieved by calling annotationlib.get_annotations() on modules, classes, and functions, respectively.

See variable annotation, function annotation, PEP 484, PEP 526, and PEP 649, which describe this functionality. Also see Annotations Best Practices for best practices on working with annotations.

argument
A value passed to a function (or method) when calling the function. There are two kinds of argument:

keyword argument: an argument preceded by an identifier (e.g. name=) in a function call or passed as a value in a dictionary preceded by **. For example, 3 and 5 are both keyword arguments in the following calls to complex():

complex(real=3, imag=5)
complex(**{'real': 3, 'imag': 5})
positional argument: an argument that is not a keyword argument. Positional arguments can appear at the beginning of an argument list and/or be passed as elements of an iterable preceded by *. For example, 3 and 5 are both positional arguments in the following calls:

complex(3, 5)
complex(*(3, 5))
Arguments are assigned to the named local variables in a function body. See the Calls section for the rules governing this assignment. Syntactically, any expression can be used to represent an argument; the evaluated value is assigned to the local variable.

See also the parameter glossary entry, the FAQ question on the difference between arguments and parameters, and PEP 362.

asynchronous context manager
An object which controls the environment seen in an async with statement by defining __aenter__() and __aexit__() methods. Introduced by PEP 492.

asynchronous generator
A function which returns an asynchronous generator iterator. It looks like a coroutine function defined with async def except that it contains yield expressions for producing a series of values usable in an async for loop.

Usually refers to an asynchronous generator function, but may refer to an asynchronous generator iterator in some contexts. In cases where the intended meaning isn’t clear, using the full terms avoids ambiguity.

An asynchronous generator function may contain await expressions as well as async for, and async with statements.

asynchronous generator iterator
An object created by an asynchronous generator function.

This is an asynchronous iterator which when called using the __anext__() method returns an awaitable object which will execute the body of the asynchronous generator function until the next yield expression.

Each yield temporarily suspends processing, remembering the execution state (including local variables and pending try-statements). When the asynchronous generator iterator effectively resumes with another awaitable returned by __anext__(), it picks up where it left off. See PEP 492 and PEP 525.

asynchronous iterable
An object, that can be used in an async for statement. Must return an asynchronous iterator from its __aiter__() method. Introduced by PEP 492.

asynchronous iterator
An object that implements the __aiter__() and __anext__() methods. __anext__() must return an awaitable object. async for resolves the awaitables returned by an asynchronous iterator’s __anext__() method until it raises a StopAsyncIteration exception. Introduced by PEP 492.

atomic operation
An operation that appears to execute as a single, indivisible step: no other thread can observe it half-done, and its effects become visible all at once. Python does not guarantee that high-level statements are atomic (for example, x += 1 performs multiple bytecode operations and is not atomic). Atomicity is only guaranteed where explicitly documented. See also race condition and data race.

attached thread state
A thread state that is active for the current OS thread.

When a thread state is attached, the OS thread has access to the full Python C API and can safely invoke the bytecode interpreter.

Unless a function explicitly notes otherwise, attempting to call the C API without an attached thread state will result in a fatal error or undefined behavior. A thread state can be attached and detached explicitly by the user through the C API, or implicitly by the runtime, including during blocking C calls and by the bytecode interpreter in between calls.

On most builds of Python, having an attached thread state implies that the caller holds the GIL for the current interpreter, so only one OS thread can have an attached thread state at a given moment. In free-threaded builds of Python, threads can concurrently hold an attached thread state, allowing for true parallelism of the bytecode interpreter.

attribute
A value associated with an object which is usually referenced by name using dotted expressions. For example, if an object o has an attribute a it would be referenced as o.a.

It is possible to give an object an attribute whose name is not an identifier as defined by Names (identifiers and keywords), for example using setattr(), if the object allows it. Such an attribute will not be accessible using a dotted expression, and would instead need to be retrieved with getattr().

awaitable
An object that can be used in an await expression. Can be a coroutine or an object with an __await__() method. See also PEP 492.

BDFL
Benevolent Dictator For Life, a.k.a. Guido van Rossum, Python’s creator.

binary file
A file object able to read and write bytes-like objects. Examples of binary files are files opened in binary mode ('rb', 'wb' or 'rb+'), sys.stdin.buffer, sys.stdout.buffer, and instances of io.BytesIO and gzip.GzipFile.

See also text file for a file object able to read and write str objects.

borrowed reference
In Python’s C API, a borrowed reference is a reference to an object, where the code using the object does not own the reference. It becomes a dangling pointer if the object is destroyed. For example, a garbage collection can remove the last strong reference to the object and so destroy it.

Calling Py_INCREF() on the borrowed reference is recommended to convert it to a strong reference in-place, except when the object cannot be destroyed before the last usage of the borrowed reference. The Py_NewRef() function can be used to create a new strong reference.

bytes-like object
An object that supports the Buffer Protocol and can export a C-contiguous buffer. This includes all bytes, bytearray, and array.array objects, as well as many common memoryview objects. Bytes-like objects can be used for various operations that work with binary data; these include compression, saving to a binary file, and sending over a socket.

Some operations need the binary data to be mutable. The documentation often refers to these as “read-write bytes-like objects”. Example mutable buffer objects include bytearray and a memoryview of a bytearray. Other operations require the binary data to be stored in immutable objects (“read-only bytes-like objects”); examples of these include bytes and a memoryview of a bytes object.

bytecode
Python source code is compiled into bytecode, the internal representation of a Python program in the CPython interpreter. The bytecode is also cached in .pyc files so that executing the same file is faster the second time (recompilation from source to bytecode can be avoided). This “intermediate language” is said to run on a virtual machine that executes the machine code corresponding to each bytecode. Do note that bytecodes are not expected to work between different Python virtual machines, nor to be stable between Python releases.

A list of bytecode instructions can be found in the documentation for the dis module.

callable
A callable is an object that can be called, possibly with a set of arguments (see argument), with the following syntax:

callable(argument1, argument2, argumentN)
A function, and by extension a method, is a callable. An instance of a class that implements the __call__() method is also a callable.

callback
A subroutine function which is passed as an argument to be executed at some point in the future.

class
A template for creating user-defined objects. Class definitions normally contain method definitions which operate on instances of the class.

class variable
A variable defined in a class and intended to be modified only at class level (i.e., not in an instance of the class).

closure variable
A free variable referenced from a nested scope that is defined in an outer scope rather than being resolved at runtime from the globals or builtin namespaces. May be explicitly defined with the nonlocal keyword to allow write access, or implicitly defined if the variable is only being read.

For example, in the inner function in the following code, both x and print are free variables, but only x is a closure variable:

def outer():
    x = 0
    def inner():
        nonlocal x
        x += 1
        print(x)
    return inner
Due to the codeobject.co_freevars attribute (which, despite its name, only includes the names of closure variables rather than listing all referenced free variables), the more general free variable term is sometimes used even when the intended meaning is to refer specifically to closure variables.

complex number
An extension of the familiar real number system in which all numbers are expressed as a sum of a real part and an imaginary part. Imaginary numbers are real multiples of the imaginary unit (the square root of -1), often written i in mathematics or j in engineering. Python has built-in support for complex numbers, which are written with this latter notation; the imaginary part is written with a j suffix, e.g., 3+1j. To get access to complex equivalents of the math module, use cmath. Use of complex numbers is a fairly advanced mathematical feature. If you’re not aware of a need for them, it’s almost certain you can safely ignore them.

concurrency
The ability of a computer program to perform multiple tasks at the same time. Python provides libraries for writing programs that make use of different forms of concurrency. asyncio is a library for dealing with asynchronous tasks and coroutines. threading provides access to operating system threads and multiprocessing to operating system processes. Multi-core processors can execute threads and processes on different CPU cores at the same time (see parallelism).

concurrent modification
When multiple threads modify shared data at the same time. Concurrent modification without proper synchronization can cause race conditions, and might also trigger a data race, data corruption, or both.

context
This term has different meanings depending on where and how it is used. Some common meanings:

The temporary state or environment established by a context manager via a with statement.

The collection of key­value bindings associated with a particular contextvars.Context object and accessed via ContextVar objects. Also see context variable.

A contextvars.Context object. Also see current context.

context management protocol
The __enter__() and __exit__() methods called by the with statement. See PEP 343.

context manager
An object which implements the context management protocol and controls the environment seen in a with statement. See PEP 343.

context variable
A variable whose value depends on which context is the current context. Values are accessed via contextvars.ContextVar objects. Context variables are primarily used to isolate state between concurrent asynchronous tasks.

contiguous
A buffer is considered contiguous exactly if it is either C-contiguous or Fortran contiguous. Zero-dimensional buffers are C and Fortran contiguous. In one-dimensional arrays, the items must be laid out in memory next to each other, in order of increasing indexes starting from zero. In multidimensional C-contiguous arrays, the last index varies the fastest when visiting items in order of memory address. However, in Fortran contiguous arrays, the first index varies the fastest.

coroutine
Coroutines are a more generalized form of subroutines. Subroutines are entered at one point and exited at another point. Coroutines can be entered, exited, and resumed at many different points. They can be implemented with the async def statement. See also PEP 492.

coroutine function
A function which returns a coroutine object. A coroutine function may be defined with the async def statement, and may contain await, async for, and async with keywords. These were introduced by PEP 492.

CPython
The canonical implementation of the Python programming language, as distributed on python.org. The term “CPython” is used when necessary to distinguish this implementation from others such as Jython or IronPython.

current context
The context (contextvars.Context object) that is currently used by ContextVar objects to access (get or set) the values of context variables. Each thread has its own current context. Frameworks for executing asynchronous tasks (see asyncio) associate each task with a context which becomes the current context whenever the task starts or resumes execution.

cyclic isolate
A subgroup of one or more objects that reference each other in a reference cycle, but are not referenced by objects outside the group. The goal of the cyclic garbage collector is to identify these groups and break the reference cycles so that the memory can be reclaimed.

data race
A situation where multiple threads access the same memory location concurrently, at least one of the accesses is a write, and the threads do not use any synchronization to control their access. Data races lead to non-deterministic behavior and can cause data corruption. Proper use of locks and other synchronization primitives prevents data races. Note that data races can only happen in native code, but that native code might be exposed in a Python API. See also race condition and thread-safe.

deadlock
A situation in which two or more tasks (threads, processes, or coroutines) wait indefinitely for each other to release resources or complete actions, preventing any from making progress. For example, if thread A holds lock 1 and waits for lock 2, while thread B holds lock 2 and waits for lock 1, both threads will wait indefinitely. In Python this often arises from acquiring multiple locks in conflicting orders or from circular join/await dependencies. Deadlocks can be avoided by always acquiring multiple locks in a consistent order. See also lock and reentrant.

decorator
A function returning another function, usually applied as a function transformation using the @wrapper syntax. Common examples for decorators are classmethod() and staticmethod().

The decorator syntax is merely syntactic sugar, the following two function definitions are semantically equivalent:

def f(arg):
    ...
f = staticmethod(f)

@staticmethod
def f(arg):
    ...
The same concept exists for classes, but is less commonly used there. See the documentation for function definitions and class definitions for more about decorators.

descriptor
Any object which defines the methods __get__(), __set__(), or __delete__(). When a class attribute is a descriptor, its special binding behavior is triggered upon attribute lookup. Normally, using a.b to get, set or delete an attribute looks up the object named b in the class dictionary for a, but if b is a descriptor, the respective descriptor method gets called. Understanding descriptors is a key to a deep understanding of Python because they are the basis for many features including functions, methods, properties, class methods, static methods, and reference to super classes.

For more information about descriptors’ methods, see Implementing Descriptors or the Descriptor How To Guide.

dictionary
An associative array, where arbitrary keys are mapped to values. The keys can be any object with __hash__() and __eq__() methods. Called a hash in Perl.

dictionary comprehension
A compact way to process all or part of the elements in an iterable and return a dictionary with the results. results = {n: n ** 2 for n in range(10)} generates a dictionary containing key n mapped to value n ** 2. See Displays for lists, sets and dictionaries.

dictionary view
The objects returned from dict.keys(), dict.values(), and dict.items() are called dictionary views. They provide a dynamic view on the dictionary’s entries, which means that when the dictionary changes, the view reflects these changes. To force the dictionary view to become a full list use list(dictview). See Dictionary view objects.

docstring
A string literal which appears as the first expression in a class, function or module. While ignored when the suite is executed, it is recognized by the compiler and put into the __doc__ attribute of the enclosing class, function or module. Since it is available via introspection, it is the canonical place for documentation of the object.

duck-typing
A programming style which does not look at an object’s type to determine if it has the right interface; instead, the method or attribute is simply called or used (“If it looks like a duck and quacks like a duck, it must be a duck.”) By emphasizing interfaces rather than specific types, well-designed code improves its flexibility by allowing polymorphic substitution. Duck-typing avoids tests using type() or isinstance(). (Note, however, that duck-typing can be complemented with abstract base classes.) Instead, it typically employs hasattr() tests or EAFP programming.

dunder
An informal short-hand for “double underscore”, used when talking about a special method. For example, __init__ is often pronounced “dunder init”.

EAFP
Easier to ask for forgiveness than permission. This common Python coding style assumes the existence of valid keys or attributes and catches exceptions if the assumption proves false. This clean and fast style is characterized by the presence of many try and except statements. The technique contrasts with the LBYL style common to many other languages such as C.

evaluate function
A function that can be called to evaluate a lazily evaluated attribute of an object, such as the value of type aliases created with the type statement.

expression
A piece of syntax which can be evaluated to some value. In other words, an expression is an accumulation of expression elements like literals, names, attribute access, operators or function calls which all return a value. In contrast to many other languages, not all language constructs are expressions. There are also statements which cannot be used as expressions, such as while. Assignments are also statements, not expressions.

extension module
A module written in C or C++, using Python’s C API to interact with the core and with user code.

f-string
f-strings
String literals prefixed with f or F are commonly called “f-strings” which is short for formatted string literals. See also PEP 498.

file object
An object exposing a file-oriented API (with methods such as read() or write()) to an underlying resource. Depending on the way it was created, a file object can mediate access to a real on-disk file or to another type of storage or communication device (for example standard input/output, in-memory buffers, sockets, pipes, etc.). File objects are also called file-like objects or streams.

There are actually three categories of file objects: raw binary files, buffered binary files and text files. Their interfaces are defined in the io module. The canonical way to create a file object is by using the open() function.

file-like object
A synonym for file object.

filesystem encoding and error handler
Encoding and error handler used by Python to decode bytes from the operating system and encode Unicode to the operating system.

The filesystem encoding must guarantee to successfully decode all bytes below 128. If the file system encoding fails to provide this guarantee, API functions can raise UnicodeError.

The sys.getfilesystemencoding() and sys.getfilesystemencodeerrors() functions can be used to get the filesystem encoding and error handler.

The filesystem encoding and error handler are configured at Python startup by the PyConfig_Read() function: see filesystem_encoding and filesystem_errors members of PyConfig.

See also the locale encoding.

finder
An object that tries to find the loader for a module that is being imported.

There are two types of finder: meta path finders for use with sys.meta_path, and path entry finders for use with sys.path_hooks.

See Finders and loaders and importlib for much more detail.

floor division
Mathematical division that rounds down to nearest integer. The floor division operator is //. For example, the expression 11 // 4 evaluates to 2 in contrast to the 2.75 returned by float true division. Note that (-11) // 4 is -3 because that is -2.75 rounded downward. See PEP 238.

free threading
A threading model where multiple threads can run Python bytecode simultaneously within the same interpreter. This is in contrast to the global interpreter lock which allows only one thread to execute Python bytecode at a time. See PEP 703.

free variable
Formally, as defined in the language execution model, a free variable is any variable used in a namespace which is not a local variable in that namespace. See closure variable for an example. Pragmatically, due to the name of the codeobject.co_freevars attribute, the term is also sometimes used as a synonym for closure variable.

function
A series of statements which returns some value to a caller. It can also be passed zero or more arguments which may be used in the execution of the body. See also parameter, method, and the Function definitions section.

function annotation
An annotation of a function parameter or return value.

Function annotations are usually used for type hints: for example, this function is expected to take two int arguments and is also expected to have an int return value:

def sum_two_numbers(a: int, b: int) -> int:
   return a + b
Function annotation syntax is explained in section Function definitions.

See variable annotation and PEP 484, which describe this functionality. Also see Annotations Best Practices for best practices on working with annotations.

__future__
A future statement, from __future__ import <feature>, directs the compiler to compile the current module using syntax or semantics that will become standard in a future release of Python. The __future__ module documents the possible values of feature. By importing this module and evaluating its variables, you can see when a new feature was first added to the language and when it will (or did) become the default:

import __future__
__future__.division
_Feature((2, 2, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0), 8192)
garbage collection
The process of freeing memory when it is not used anymore. Python performs garbage collection via reference counting and a cyclic garbage collector that is able to detect and break reference cycles. The garbage collector can be controlled using the gc module.

generator
A function which returns a generator iterator. It looks like a normal function except that it contains yield expressions for producing a series of values usable in a for-loop or that can be retrieved one at a time with the next() function.

Usually refers to a generator function, but may refer to a generator iterator in some contexts. In cases where the intended meaning isn’t clear, using the full terms avoids ambiguity.

generator iterator
An object created by a generator function.

Each yield temporarily suspends processing, remembering the execution state (including local variables and pending try-statements). When the generator iterator resumes, it picks up where it left off (in contrast to functions which start fresh on every invocation).

generator expression
An expression that returns an iterator. It looks like a normal expression followed by a for clause defining a loop variable, range, and an optional if clause. The combined expression generates values for an enclosing function:

sum(i*i for i in range(10))         # sum of squares 0, 1, 4, ... 81
285
generic function
A function composed of multiple functions implementing the same operation for different types. Which implementation should be used during a call is determined by the dispatch algorithm.

See also the single dispatch glossary entry, the functools.singledispatch() decorator, and PEP 443.

generic type
A type that can be parameterized; typically a container class such as list or dict. Used for type hints and annotations.

For more details, see generic alias types, PEP 483, PEP 484, PEP 585, and the typing module.

GIL
See global interpreter lock.

global interpreter lock
The mechanism used by the CPython interpreter to assure that only one thread executes Python bytecode at a time. This simplifies the CPython implementation by making the object model (including critical built-in types such as dict) implicitly safe against concurrent access. Locking the entire interpreter makes it easier for the interpreter to be multi-threaded, at the expense of much of the parallelism afforded by multi-processor machines.

However, some extension modules, either standard or third-party, are designed so as to release the GIL when doing computationally intensive tasks such as compression or hashing. Also, the GIL is always released when doing I/O.

As of Python 3.13, the GIL can be disabled using the --disable-gil build configuration. After building Python with this option, code must be run with -X gil=0 or after setting the PYTHON_GIL=0 environment variable. This feature enables improved performance for multi-threaded applications and makes it easier to use multi-core CPUs efficiently. For more details, see PEP 703.

In prior versions of Python’s C API, a function might declare that it requires the GIL to be held in order to use it. This refers to having an attached thread state.

global state
Data that is accessible throughout a program, such as module-level variables, class variables, or C static variables in extension modules. In multi-threaded programs, global state shared between threads typically requires synchronization to avoid race conditions and data races.

hash-based pyc
A bytecode cache file that uses the hash rather than the last-modified time of the corresponding source file to determine its validity. See Cached bytecode invalidation.

hashable
An object is hashable if it has a hash value which never changes during its lifetime (it needs a __hash__() method), and can be compared to other objects (it needs an __eq__() method). Hashable objects which compare equal must have the same hash value.

Hashability makes an object usable as a dictionary key and a set member, because these data structures use the hash value internally.

Most of Python’s immutable built-in objects are hashable; mutable containers (such as lists or dictionaries) are not; immutable containers (such as tuples and frozensets) are only hashable if their elements are hashable. Objects which are instances of user-defined classes are hashable by default. They all compare unequal (except with themselves), and their hash value is derived from their id().

IDLE
An Integrated Development and Learning Environment for Python. IDLE — Python editor and shell is a basic editor and interpreter environment which ships with the standard distribution of Python.

immortal
Immortal objects are a CPython implementation detail introduced in PEP 683.

If an object is immortal, its reference count is never modified, and therefore it is never deallocated while the interpreter is running. For example, True and None are immortal in CPython.

Immortal objects can be identified via sys._is_immortal(), or via PyUnstable_IsImmortal() in the C API.

immutable
An object with a fixed value. Immutable objects include numbers, strings and tuples. Such an object cannot be altered. A new object has to be created if a different value has to be stored. They play an important role in places where a constant hash value is needed, for example as a key in a dictionary. Immutable objects are inherently thread-safe because their state cannot be modified after creation, eliminating concerns about improperly synchronized concurrent modification.

import path
A list of locations (or path entries) that are searched by the path based finder for modules to import. During import, this list of locations usually comes from sys.path, but for subpackages it may also come from the parent package’s __path__ attribute.

importing
The process by which Python code in one module is made available to Python code in another module.

importer
An object that both finds and loads a module; both a finder and loader object.

interactive
Python has an interactive interpreter which means you can enter statements and expressions at the interpreter prompt, immediately execute them and see their results. Just launch python with no arguments (possibly by selecting it from your computer’s main menu). It is a very powerful way to test out new ideas or inspect modules and packages (remember help(x)). For more on interactive mode, see Interactive Mode.

interpreted
Python is an interpreted language, as opposed to a compiled one, though the distinction can be blurry because of the presence of the bytecode compiler. This means that source files can be run directly without explicitly creating an executable which is then run. Interpreted languages typically have a shorter development/debug cycle than compiled ones, though their programs generally also run more slowly. See also interactive.

interpreter shutdown
When asked to shut down, the Python interpreter enters a special phase where it gradually releases all allocated resources, such as modules and various critical internal structures. It also makes several calls to the garbage collector. This can trigger the execution of code in user-defined destructors or weakref callbacks. Code executed during the shutdown phase can encounter various exceptions as the resources it relies on may not function anymore (common examples are library modules or the warnings machinery).

The main reason for interpreter shutdown is that the __main__ module or the script being run has finished executing.

iterable
An object capable of returning its members one at a time. Examples of iterables include all sequence types (such as list, str, and tuple) and some non-sequence types like dict, file objects, and objects of any classes you define with an __iter__() method or with a __getitem__() method that implements sequence semantics.

Iterables can be used in a for loop and in many other places where a sequence is needed (zip(), map(), …). When an iterable object is passed as an argument to the built-in function iter(), it returns an iterator for the object. This iterator is good for one pass over the set of values. When using iterables, it is usually not necessary to call iter() or deal with iterator objects yourself. The for statement does that automatically for you, creating a temporary unnamed variable to hold the iterator for the duration of the loop. See also iterator, sequence, and generator.

iterator
An object representing a stream of data. Repeated calls to the iterator’s __next__() method (or passing it to the built-in function next()) return successive items in the stream. When no more data are available a StopIteration exception is raised instead. At this point, the iterator object is exhausted and any further calls to its __next__() method just raise StopIteration again. Iterators are required to have an __iter__() method that returns the iterator object itself so every iterator is also iterable and may be used in most places where other iterables are accepted. One notable exception is code which attempts multiple iteration passes. A container object (such as a list) produces a fresh new iterator each time you pass it to the iter() function or use it in a for loop. Attempting this with an iterator will just return the same exhausted iterator object used in the previous iteration pass, making it appear like an empty container.

More information can be found in Iterator Types.

CPython implementation detail: CPython does not consistently apply the requirement that an iterator define __iter__(). And also please note that free-threaded CPython does not guarantee thread-safe behavior of iterator operations.

key function
A key function or collation function is a callable that returns a value used for sorting or ordering. For example, locale.strxfrm() is used to produce a sort key that is aware of locale specific sort conventions.

A number of tools in Python accept key functions to control how elements are ordered or grouped. They include min(), max(), sorted(), list.sort(), heapq.merge(), heapq.nsmallest(), heapq.nlargest(), and itertools.groupby().

There are several ways to create a key function. For example. the str.casefold() method can serve as a key function for case insensitive sorts. Alternatively, a key function can be built from a lambda expression such as lambda r: (r[0], r[2]). Also, operator.attrgetter(), operator.itemgetter(), and operator.methodcaller() are three key function constructors. See the Sorting HOW TO for examples of how to create and use key functions.

keyword argument
See argument.

lambda
An anonymous inline function consisting of a single expression which is evaluated when the function is called. The syntax to create a lambda function is lambda [parameters]: expression

LBYL
Look before you leap. This coding style explicitly tests for pre-conditions before making calls or lookups. This style contrasts with the EAFP approach and is characterized by the presence of many if statements.

In a multi-threaded environment, the LBYL approach can risk introducing a race condition between “the looking” and “the leaping”. For example, the code, if key in mapping: return mapping[key] can fail if another thread removes key from mapping after the test, but before the lookup. This issue can be solved with locks or by using the EAFP approach. See also thread-safe.

lexical analyzer
Formal name for the tokenizer; see token.

list
A built-in Python sequence. Despite its name it is more akin to an array in other languages than to a linked list since access to elements is O(1).

list comprehension
A compact way to process all or part of the elements in a sequence and return a list with the results. result = ['{:#04x}'.format(x) for x in range(256) if x % 2 == 0] generates a list of strings containing even hex numbers (0x..) in the range from 0 to 255. The if clause is optional. If omitted, all elements in range(256) are processed.

lock
A synchronization primitive that allows only one thread at a time to access a shared resource. A thread must acquire a lock before accessing the protected resource and release it afterward. If a thread attempts to acquire a lock that is already held by another thread, it will block until the lock becomes available. Python’s threading module provides Lock (a basic lock) and RLock (a reentrant lock). Locks are used to prevent race conditions and ensure thread-safe access to shared data. Alternative design patterns to locks exist such as queues, producer/consumer patterns, and thread-local state. See also deadlock, and reentrant.

loader
An object that loads a module. It must define the exec_module() and create_module() methods to implement the Loader interface. A loader is typically returned by a finder. See also:

Finders and loaders

importlib.abc.Loader

PEP 302

locale encoding
On Unix, it is the encoding of the LC_CTYPE locale. It can be set with locale.setlocale(locale.LC_CTYPE, new_locale).

On Windows, it is the ANSI code page (ex: ""cp1252"").

On Android and VxWorks, Python uses ""utf-8"" as the locale encoding.

locale.getencoding() can be used to get the locale encoding.

See also the filesystem encoding and error handler.

magic method
An informal synonym for special method.

mapping
A container object that supports arbitrary key lookups and implements the methods specified in the collections.abc.Mapping or collections.abc.MutableMapping abstract base classes. Examples include dict, collections.defaultdict, collections.OrderedDict and collections.Counter.

meta path finder
A finder returned by a search of sys.meta_path. Meta path finders are related to, but different from path entry finders.

See importlib.abc.MetaPathFinder for the methods that meta path finders implement.

metaclass
The class of a class. Class definitions create a class name, a class dictionary, and a list of base classes. The metaclass is responsible for taking those three arguments and creating the class. Most object oriented programming languages provide a default implementation. What makes Python special is that it is possible to create custom metaclasses. Most users never need this tool, but when the need arises, metaclasses can provide powerful, elegant solutions. They have been used for logging attribute access, adding thread-safety, tracking object creation, implementing singletons, and many other tasks.

More information can be found in Metaclasses.

method
A function which is defined inside a class body. If called as an attribute of an instance of that class, the method will get the instance object as its first argument (which is usually called self). See function and nested scope.

method resolution order
Method Resolution Order is the order in which base classes are searched for a member during lookup. See The Python 2.3 Method Resolution Order for details of the algorithm used by the Python interpreter since the 2.3 release.

module
An object that serves as an organizational unit of Python code. Modules have a namespace containing arbitrary Python objects. Modules are loaded into Python by the process of importing.

See also package.

module spec
A namespace containing the import-related information used to load a module. An instance of importlib.machinery.ModuleSpec.

See also Module specs.

MRO
See method resolution order.

mutable
An object with state that is allowed to change during the course of the program. In multi-threaded programs, mutable objects that are shared between threads require careful synchronization to avoid race conditions. See also immutable, thread-safe, and concurrent modification.

named tuple
The term “named tuple” applies to any type or class that inherits from tuple and whose indexable elements are also accessible using named attributes. The type or class may have other features as well.

Several built-in types are named tuples, including the values returned by time.localtime() and os.stat(). Another example is sys.float_info:

sys.float_info[1]                   # indexed access
1024
sys.float_info.max_exp              # named field access
1024
isinstance(sys.float_info, tuple)   # kind of tuple
True
Some named tuples are built-in types (such as the above examples). Alternatively, a named tuple can be created from a regular class definition that inherits from tuple and that defines named fields. Such a class can be written by hand, or it can be created by inheriting typing.NamedTuple, or with the factory function collections.namedtuple(). The latter techniques also add some extra methods that may not be found in hand-written or built-in named tuples.

namespace
The place where a variable is stored. Namespaces are implemented as dictionaries. There are the local, global and built-in namespaces as well as nested namespaces in objects (in methods). Namespaces support modularity by preventing naming conflicts. For instance, the functions builtins.open and os.open() are distinguished by their namespaces. Namespaces also aid readability and maintainability by making it clear which module implements a function. For instance, writing random.seed() or itertools.islice() makes it clear that those functions are implemented by the random and itertools modules, respectively.

namespace package
A package which serves only as a container for subpackages. Namespace packages may have no physical representation, and specifically are not like a regular package because they have no __init__.py file.

Namespace packages allow several individually installable packages to have a common parent package. Otherwise, it is recommended to use a regular package.

For more information, see PEP 420 and Namespace packages.

See also module.

native code
Code that is compiled to machine instructions and runs directly on the processor, as opposed to code that is interpreted or runs in a virtual machine. In the context of Python, native code typically refers to C, C++, Rust or Fortran code in extension modules that can be called from Python. See also extension module.

nested scope
The ability to refer to a variable in an enclosing definition. For instance, a function defined inside another function can refer to variables in the outer function. Note that nested scopes by default work only for reference and not for assignment. Local variables both read and write in the innermost scope. Likewise, global variables read and write to the global namespace. The nonlocal allows writing to outer scopes.

new-style class
Old name for the flavor of classes now used for all class objects. In earlier Python versions, only new-style classes could use Python’s newer, versatile features like __slots__, descriptors, properties, __getattribute__(), class methods, and static methods.

non-deterministic
Behavior where the outcome of a program can vary between executions with the same inputs. In multi-threaded programs, non-deterministic behavior often results from race conditions where the relative timing or interleaving of threads affects the result. Proper synchronization using locks and other synchronization primitives helps ensure deterministic behavior.

object
Any data with state (attributes or value) and defined behavior (methods). Also the ultimate base class of any new-style class.

optimized scope
A scope where target local variable names are reliably known to the compiler when the code is compiled, allowing optimization of read and write access to these names. The local namespaces for functions, generators, coroutines, comprehensions, and generator expressions are optimized in this fashion. Note: most interpreter optimizations are applied to all scopes, only those relying on a known set of local and nonlocal variable names are restricted to optimized scopes.

optional module
An extension module that is part of the standard library, but may be absent in some builds of CPython, usually due to missing third-party libraries or because the module is not available for a given platform.

See Requirements for optional modules for a list of optional modules that require third-party libraries.

package
A Python module which can contain submodules or recursively, subpackages. Technically, a package is a Python module with a __path__ attribute.

See also regular package and namespace package.

parallelism
Executing multiple operations at the same time (e.g. on multiple CPU cores). In Python builds with the global interpreter lock (GIL), only one thread runs Python bytecode at a time, so taking advantage of multiple CPU cores typically involves multiple processes (e.g. multiprocessing) or native extensions that release the GIL. In free-threaded Python, multiple Python threads can run Python code simultaneously on different cores.

parameter
A named entity in a function (or method) definition that specifies an argument (or in some cases, arguments) that the function can accept. There are five kinds of parameter:

positional-or-keyword: specifies an argument that can be passed either positionally or as a keyword argument. This is the default kind of parameter, for example foo and bar in the following:

def func(foo, bar=None): ...
positional-only: specifies an argument that can be supplied only by position. Positional-only parameters can be defined by including a / character in the parameter list of the function definition after them, for example posonly1 and posonly2 in the following:

def func(posonly1, posonly2, /, positional_or_keyword): ...
keyword-only: specifies an argument that can be supplied only by keyword. Keyword-only parameters can be defined by including a single var-positional parameter or bare * in the parameter list of the function definition before them, for example kw_only1 and kw_only2 in the following:

def func(arg, *, kw_only1, kw_only2): ...
var-positional: specifies that an arbitrary sequence of positional arguments can be provided (in addition to any positional arguments already accepted by other parameters). Such a parameter can be defined by prepending the parameter name with *, for example args in the following:

def func(*args, **kwargs): ...
var-keyword: specifies that arbitrarily many keyword arguments can be provided (in addition to any keyword arguments already accepted by other parameters). Such a parameter can be defined by prepending the parameter name with **, for example kwargs in the example above.

Parameters can specify both optional and required arguments, as well as default values for some optional arguments.

See also the argument glossary entry, the FAQ question on the difference between arguments and parameters, the inspect.Parameter class, the Function definitions section, and PEP 362.

path entry
A single location on the import path which the path based finder consults to find modules for importing.

path entry finder
A finder returned by a callable on sys.path_hooks (i.e. a path entry hook) which knows how to locate modules given a path entry.

See importlib.abc.PathEntryFinder for the methods that path entry finders implement.

path entry hook
A callable on the sys.path_hooks list which returns a path entry finder if it knows how to find modules on a specific path entry.

path based finder
One of the default meta path finders which searches an import path for modules.

path-like object
An object representing a file system path. A path-like object is either a str or bytes object representing a path, or an object implementing the os.PathLike protocol. An object that supports the os.PathLike protocol can be converted to a str or bytes file system path by calling the os.fspath() function; os.fsdecode() and os.fsencode() can be used to guarantee a str or bytes result instead, respectively. Introduced by PEP 519.

PEP
Python Enhancement Proposal. A PEP is a design document providing information to the Python community, or describing a new feature for Python or its processes or environment. PEPs should provide a concise technical specification and a rationale for proposed features.

PEPs are intended to be the primary mechanisms for proposing major new features, for collecting community input on an issue, and for documenting the design decisions that have gone into Python. The PEP author is responsible for building consensus within the community and documenting dissenting opinions.

See PEP 1.

portion
A set of files in a single directory (possibly stored in a zip file) that contribute to a namespace package, as defined in PEP 420.

positional argument
See argument.

provisional API
A provisional API is one which has been deliberately excluded from the standard library’s backwards compatibility guarantees. While major changes to such interfaces are not expected, as long as they are marked provisional, backwards incompatible changes (up to and including removal of the interface) may occur if deemed necessary by core developers. Such changes will not be made gratuitously – they will occur only if serious fundamental flaws are uncovered that were missed prior to the inclusion of the API.

Even for provisional APIs, backwards incompatible changes are seen as a “solution of last resort” - every attempt will still be made to find a backwards compatible resolution to any identified problems.

This process allows the standard library to continue to evolve over time, without locking in problematic design errors for extended periods of time. See PEP 411 for more details.

provisional package
See provisional API.

Python 3000
Nickname for the Python 3.x release line (coined long ago when the release of version 3 was something in the distant future.) This is also abbreviated “Py3k”.

Pythonic
An idea or piece of code which closely follows the most common idioms of the Python language, rather than implementing code using concepts common to other languages. For example, a common idiom in Python is to loop over all elements of an iterable using a for statement. Many other languages don’t have this type of construct, so people unfamiliar with Python sometimes use a numerical counter instead:

for i in range(len(food)):
    print(food[i])
As opposed to the cleaner, Pythonic method:

for piece in food:
    print(piece)
qualified name
A dotted name showing the “path” from a module’s global scope to a class, function or method defined in that module, as defined in PEP 3155. For top-level functions and classes, the qualified name is the same as the object’s name:

class C:
    class D:
        def meth(self):
            pass

C.__qualname__
'C'
C.D.__qualname__
'C.D'
C.D.meth.__qualname__
'C.D.meth'
When used to refer to modules, the fully qualified name means the entire dotted path to the module, including any parent packages, e.g. email.mime.text:

import email.mime.text
email.mime.text.__name__
'email.mime.text'
race condition
A condition of a program where the its behavior depends on the relative timing or ordering of events, particularly in multi-threaded programs. Race conditions can lead to non-deterministic behavior and bugs that are difficult to reproduce. A data race is a specific type of race condition involving unsynchronized access to shared memory. The LBYL coding style is particularly susceptible to race conditions in multi-threaded code. Using locks and other synchronization primitives helps prevent race conditions.

reference count
The number of references to an object. When the reference count of an object drops to zero, it is deallocated. Some objects are immortal and have reference counts that are never modified, and therefore the objects are never deallocated. Reference counting is generally not visible to Python code, but it is a key element of the CPython implementation. Programmers can call the sys.getrefcount() function to return the reference count for a particular object.

In CPython, reference counts are not considered to be stable or well-defined values; the number of references to an object, and how that number is affected by Python code, may be different between versions.

regular package
A traditional package, such as a directory containing an __init__.py file.

See also namespace package.

reentrant
A property of a function or lock that allows it to be called or acquired multiple times by the same thread without causing errors or a deadlock.

For functions, reentrancy means the function can be safely called again before a previous invocation has completed, which is important when functions may be called recursively or from signal handlers. Thread-unsafe functions may be non-deterministic if they’re called reentrantly in a multithreaded program.

For locks, Python’s threading.RLock (reentrant lock) is reentrant, meaning a thread that already holds the lock can acquire it again without blocking. In contrast, threading.Lock is not reentrant - attempting to acquire it twice from the same thread will cause a deadlock.

See also lock and deadlock.

REPL
An acronym for the “read–eval–print loop”, another name for the interactive interpreter shell.

__slots__
A declaration inside a class that saves memory by pre-declaring space for instance attributes and eliminating instance dictionaries. Though popular, the technique is somewhat tricky to get right and is best reserved for rare cases where there are large numbers of instances in a memory-critical application.

sequence
An iterable which supports efficient element access using integer indices via the __getitem__() special method and defines a __len__() method that returns the length of the sequence. Some built-in sequence types are list, str, tuple, and bytes. Note that dict also supports __getitem__() and __len__(), but is considered a mapping rather than a sequence because the lookups use arbitrary hashable keys rather than integers.

The collections.abc.Sequence abstract base class defines a much richer interface that goes beyond just __getitem__() and __len__(), adding count(), index(), __contains__(), and __reversed__(). Types that implement this expanded interface can be registered explicitly using register(). For more documentation on sequence methods generally, see Common Sequence Operations.

set comprehension
A compact way to process all or part of the elements in an iterable and return a set with the results. results = {c for c in 'abracadabra' if c not in 'abc'} generates the set of strings {'r', 'd'}. See Displays for lists, sets and dictionaries.

single dispatch
A form of generic function dispatch where the implementation is chosen based on the type of a single argument.

slice
An object usually containing a portion of a sequence. A slice is created using the subscript notation, [] with colons between numbers when several are given, such as in variable_name[1:3:5]. The bracket (subscript) notation uses slice objects internally.

soft deprecated
A soft deprecated API should not be used in new code, but it is safe for already existing code to use it. The API remains documented and tested, but will not be enhanced further.

Soft deprecation, unlike normal deprecation, does not plan on removing the API and will not emit warnings.

See PEP 387: Soft Deprecation.

special method
A method that is called implicitly by Python to execute a certain operation on a type, such as addition. Such methods have names starting and ending with double underscores. Special methods are documented in Special method names.

standard library
The collection of packages, modules and extension modules distributed as a part of the official Python interpreter package. The exact membership of the collection may vary based on platform, available system libraries, or other criteria. Documentation can be found at The Python Standard Library.

See also sys.stdlib_module_names for a list of all possible standard library module names.

statement
A statement is part of a suite (a “block” of code). A statement is either an expression or one of several constructs with a keyword, such as if, while or for.

static type checker
An external tool that reads Python code and analyzes it, looking for issues such as incorrect types. See also type hints and the typing module.

stdlib
An abbreviation of standard library.

strong reference
In Python’s C API, a strong reference is a reference to an object which is owned by the code holding the reference. The strong reference is taken by calling Py_INCREF() when the reference is created and released with Py_DECREF() when the reference is deleted.

The Py_NewRef() function can be used to create a strong reference to an object. Usually, the Py_DECREF() function must be called on the strong reference before exiting the scope of the strong reference, to avoid leaking one reference.

See also borrowed reference.

synchronization primitive
A basic building block for coordinating (synchronizing) the execution of multiple threads to ensure thread-safe access to shared resources. Python’s threading module provides several synchronization primitives including Lock, RLock, Semaphore, Condition, Event, and Barrier. Additionally, the queue module provides multi-producer, multi-consumer queues that are especially useful in multithreaded programs. These primitives help prevent race conditions and coordinate thread execution. See also lock.

t-string
t-strings
String literals prefixed with t or T are commonly called “t-strings” which is short for template string literals.

text encoding
A string in Python is a sequence of Unicode code points (in range U+0000–U+10FFFF). To store or transfer a string, it needs to be serialized as a sequence of bytes.

Serializing a string into a sequence of bytes is known as “encoding”, and recreating the string from the sequence of bytes is known as “decoding”.

There are a variety of different text serialization codecs, which are collectively referred to as “text encodings”.

text file
A file object able to read and write str objects. Often, a text file actually accesses a byte-oriented datastream and handles the text encoding automatically. Examples of text files are files opened in text mode ('r' or 'w'), sys.stdin, sys.stdout, and instances of io.StringIO.

See also binary file for a file object able to read and write bytes-like objects.

thread state
The information used by the CPython runtime to run in an OS thread. For example, this includes the current exception, if any, and the state of the bytecode interpreter.

Each thread state is bound to a single OS thread, but threads may have many thread states available. At most, one of them may be attached at once.

An attached thread state is required to call most of Python’s C API, unless a function explicitly documents otherwise. The bytecode interpreter only runs under an attached thread state.

Each thread state belongs to a single interpreter, but each interpreter may have many thread states, including multiple for the same OS thread. Thread states from multiple interpreters may be bound to the same thread, but only one can be attached in that thread at any given moment.

See Thread State and the Global Interpreter Lock for more information.

thread-safe
A module, function, or class that behaves correctly when used by multiple threads concurrently. Thread-safe code uses appropriate synchronization primitives like locks to protect shared mutable state, or is designed to avoid shared mutable state entirely. In the free-threaded build, built-in types like dict, list, and set use internal locking to make many operations thread-safe, although thread safety is not necessarily guaranteed. Code that is not thread-safe may experience race conditions and data races when used in multi-threaded programs.

token
A small unit of source code, generated by the lexical analyzer (also called the tokenizer). Names, numbers, strings, operators, newlines and similar are represented by tokens.

The tokenize module exposes Python’s lexical analyzer. The token module contains information on the various types of tokens.

triple-quoted string
A string which is bound by three instances of either a quotation mark (”) or an apostrophe (‘). While they don’t provide any functionality not available with single-quoted strings, they are useful for a number of reasons. They allow you to include unescaped single and double quotes within a string and they can span multiple lines without the use of the continuation character, making them especially useful when writing docstrings.

type
The type of a Python object determines what kind of object it is; every object has a type. An object’s type is accessible as its __class__ attribute or can be retrieved with type(obj).

type alias
A synonym for a type, created by assigning the type to an identifier.

Type aliases are useful for simplifying type hints. For example:

def remove_gray_shades(
        colors: list[tuple[int, int, int]]) -> list[tuple[int, int, int]]:
    pass
could be made more readable like this:

Color = tuple[int, int, int]

def remove_gray_shades(colors: list[Color]) -> list[Color]:
    pass
See typing and PEP 484, which describe this functionality.

type hint
An annotation that specifies the expected type for a variable, a class attribute, or a function parameter or return value.

Type hints are optional and are not enforced by Python but they are useful to static type checkers. They can also aid IDEs with code completion and refactoring.

Type hints of global variables, class attributes, and functions, but not local variables, can be accessed using typing.get_type_hints().

See typing and PEP 484, which describe this functionality.

universal newlines
A manner of interpreting text streams in which all of the following are recognized as ending a line: the Unix end-of-line convention '\n', the Windows convention '\r\n', and the old Macintosh convention '\r'. See PEP 278 and PEP 3116, as well as bytes.splitlines() for an additional use.

variable annotation
An annotation of a variable or a class attribute.

When annotating a variable or a class attribute, assignment is optional:

class C:
    field: 'annotation'
Variable annotations are usually used for type hints: for example this variable is expected to take int values:

count: int = 0
Variable annotation syntax is explained in section Annotated assignment statements.

See function annotation, PEP 484 and PEP 526, which describe this functionality. Also see Annotations Best Practices for best practices on working with annotations.

virtual environment
A cooperatively isolated runtime environment that allows Python users and applications to install and upgrade Python distribution packages without interfering with the behaviour of other Python applications running on the same system.

See also venv.

virtual machine
A computer defined entirely in software. Python’s virtual machine executes the bytecode emitted by the bytecode compiler.

walrus operator
A light-hearted way to refer to the assignment expression operator := because it looks a bit like a walrus if you turn your head.

Zen of Python
Listing of Python design principles and philosophies that are helpful in understanding and using the language. The listing can be found by typing “import this” at the interactive prompt"
"python_idle_dependencies_documentation","Documentation","Med","3.14.2","python, idle, documentation, dependencies_installation ","Regenerate configure
If a change is made to Python which relies on some POSIX system-specific functionality (such as using a new system call), it is necessary to update the configure script to test for availability of the functionality. Python’s configure script is generated from configure.ac using GNU Autoconf.

After editing configure.ac, run make regen-configure to generate configure, pyconfig.h.in, and aclocal.m4. When submitting a pull request with changes made to configure.ac, make sure you also commit the changes in the generated files.

Python’s configure.ac script requires a specific version of GNU Autoconf. For Python 3.12 and newer, GNU Autoconf v2.71 is required. For Python 3.11 and earlier, GNU Autoconf v2.69 is required.

The recommended and by far the easiest way to regenerate configure is:

make regen-configure
This will use Podman or Docker to do the regeneration with the proper version of GNU Autoconf.

If you cannot (or don’t want to) use make regen-configure, install the autoconf-archive and pkg-config utilities, and make sure the pkg.m4 macro file located in the appropriate aclocal location:

ls $(aclocal --print-ac-dir) | grep pkg.m4
Note

Running autoreconf is not the same as running autoconf. For example, running autoconf by itself will not regenerate pyconfig.h.in. autoreconf runs autoconf and a number of other tools repeatedly as appropriate.

Regenerate the ABI dump
Maintenance branches (not main) have a special file located in Doc/data/pythonX.Y.abi that allows us to know if a given pull request affects the public ABI. This file is used by the GitHub CI in a check called Check if the ABI has changed that will fail if a given pull request has changes to the ABI and the ABI file is not updated.

This check acts as a fail-safe and doesn’t necessarily mean that the pull request cannot be merged. When this check fails you should add the relevant release manager to the PR so that they are aware of the change and they can validate if the change can be made or not.

Important

ABI changes are allowed before the first release candidate. After the first release candidate, all further releases must have the same ABI for ensuring compatibility with native extensions and other tools that interact with the Python interpreter. See the documentation about the release candidate phase.

When the PR check fails, the associated run will have the updated ABI file attached as an artifact. After release manager approval, you can download and add this file into your PR to pass the check.

You can regenerate the ABI file by yourself by invoking the regen abidump Make target. Note that for doing this you need to regenerate the ABI file in the same environment that the GitHub CI uses to check for it. This is because different platforms may include some platform-specific details that make the check fail even if the Python ABI is the same. The easier way to regenerate the ABI file using the same platform as the CI uses is by using Docker:

In the CPython root:
docker run -v$(pwd):/src:Z -w /src --rm -it ubuntu:22.04 \
    bash /src/.github/workflows/regen-abidump.sh
Note that the ubuntu version used to execute the script matters and must match the version used by the CI to check the ABI. See the .github/workflows/build.yml file for more information.

Troubleshoot the build
This section lists some of the common problems that may arise during the compilation of Python, with proposed solutions.

Avoid recreating auto-generated files
Under some circumstances you may encounter Python errors in scripts like Parser/asdl_c.py or Python/makeopcodetargets.py while running make. Python auto-generates some of its own code, and a full build from scratch needs to run the auto-generation scripts. However, this makes the Python build require an already installed Python interpreter; this can also cause version mismatches when trying to build an old (2.x) Python with a new (3.x) Python installed, or vice versa.

To overcome this problem, auto-generated files are also checked into the Git repository. So if you don’t touch the auto-generation scripts, there’s no real need to auto-generate anything.

Editors and tools
Python is used widely enough that practically all code editors have some form of support for writing Python code. Various coding tools also include Python support.

For editors and tools which the core developers have felt some special comment is needed for coding in Python, see Additional resources.

Directory structure
There are several top-level directories in the CPython source tree. Knowing what each one is meant to hold will help you find where a certain piece of functionality is implemented. Do realize, though, there are always exceptions to every rule.

Doc
The official documentation. This is what https://docs.python.org/ uses. See also Building the documentation.

Grammar
Contains the PEG grammar file for Python.

Include
Contains all interpreter-wide header files.

Lib
The part of the standard library implemented in pure Python.

Mac
Mac-specific code (for example, using IDLE as a macOS application).

Misc
Things that do not belong elsewhere. Typically this is varying kinds of developer-specific documentation.

Modules
The part of the standard library (plus some other code) that is implemented in C.

Objects
Code for all built-in types.

PC
Windows-specific code.

PCbuild
Build files for the version of MSVC currently used for the Windows installers provided on python.org.

Parser
Code related to the parser. The definition of the AST nodes is also kept here.

Programs
Source code for C executables, including the main function for the CPython interpreter.

Python
The code that makes up the core CPython runtime. This includes the compiler, eval loop and various built-in modules.

Tools
Various tools that are (or have been) used to maintain Python.

Using a container
There are various ways to use a container to build CPython without installing additional tools on your machine. All approaches use the container defined in the cpython-devcontainers repo in some way.

Contribute using GitHub Codespaces
What is GitHub Codespaces?
If you’d like to start contributing to CPython without needing to set up a local developer environment, you can use GitHub Codespaces. Codespaces is a cloud-based development environment offered by GitHub that allows developers to write, build, test, and debug code directly within their web browser or in Visual Studio Code (VS Code).

To help you get started, CPython contains a devcontainer folder with a JSON configuration file that provides consistent and versioned codespace configurations for all users of the project. It also contains a Dockerfile that allows you to set up the same environment but locally in a Docker container if you’d prefer to use that directly.

Create a CPython codespace
Here are the basic steps needed to contribute a pull request using Codespaces. You first need to navigate to the CPython repo hosted on GitHub.

Then you will need to:

Launch the codespace

Press the , key to launch the codespace setup screen for the current branch

For the default dev container (which is what you very likely want), click the green Create new codespace button

For alternative containers, click Change options and choose the appropriate container

Alternatively, click the green Code button and choose the codespaces tab

For the default dev container (which is what you very likely want), click the green Create codespace on main button

For alternative containers, go to the … menu and choose New with options…

A screen should appear that lets you know your codespace is being set up. (Note: Since the CPython devcontainer is provided, codespaces will use the configuration it specifies.)

A web version of VS Code will open inside your web browser, already linked up with your code and a terminal to the remote codespace where CPython and its documentation have already been built.

Use the terminal with the usual Git commands to create a new branch, commit and push your changes once you’re ready!

If you close your repository and come back later you can always resume your codespace by navigating to the CPython repo, selecting the codespaces tab and selecting your most recent codespaces session. You should then be able to pick up from where you left off!

Use Codespaces locally
On the bottom left side of the codespace screen you will see a green or grey square that says Codespaces. You can click this for additional options. If you prefer working in a locally installed copy of VS Code you can select the option Open in VS Code. You will still be working on the remote codespace instance, thus using the remote instance’s compute power. The compute power may be a much higher spec than your local machine which can be helpful.

Using the dev container directly
If you want more control over the environment, or to work offline, you can use the same container used in GitHub Codespaces directly. This is meant for users who have (or want to get) some experience with containers. These instructions assume a Unix-like environment with Docker or Podman installed. The instructions also assume you want the default dev container; tweak the commands as appropriate if you want to use an alternative container (e.g. the WASI dev container).

Using the pre-built container image
Dev container images are available from the GitHub Container Registry (GHCR) account for the Python org.

To run the container and launch a Bash shell, run one of the following commands in a clone of the CPython repository.


Podman
podman run -it --rm --volume $PWD:/workspace:Z --workdir /workspace ghcr.io/python/devcontainer:latest

Docker
Note that the container has read/write access to the working directory. You may want to use a separate clone of CPython, or run make clean to remove caches and build output generated for your host OS.

Building yourself
If you prefer, you can build the container image yourself. In a clone of the cpython-devcontainers repo, build the container and name it cpython-dev:


Podman
podman build devcontainer/ --tag cpython-dev

Docker
The same command will update any existing cpython-dev container. Run it again from time to time – especially if the container stops working for you.

To run the container and launch a Bash shell, run one of the following commands in a clone of the CPython repository.


Podman
podman run -it --rm --volume $PWD:/workspace:Z --workdir /workspace cpython-dev bash

Docker
The same caveats outlined above when running from a container image from GHCR also apply here."
"IDLE_Python_editor_and_shell","Documentation","Priority","3.14","Python, IDLE,","Source code: Lib/idlelib/

IDLE is Python’s Integrated Development and Learning Environment.

IDLE has the following features:

cross-platform: works mostly the same on Windows, Unix, and macOS

Python shell window (interactive interpreter) with colorizing of code input, output, and error messages

multi-window text editor with multiple undo, Python colorizing, smart indent, call tips, auto completion, and other features

search within any window, replace within editor windows, and search through multiple files (grep)

debugger with persistent breakpoints, stepping, and viewing of global and local namespaces

configuration, browsers, and other dialogs

The IDLE application is implemented in the idlelib package.

This is an optional module. If it is missing from your copy of CPython, look for documentation from your distributor (that is, whoever provided Python to you). If you are the distributor, see Requirements for optional modules.

Menus
IDLE has two main window types, the Shell window and the Editor window. It is possible to have multiple editor windows simultaneously. On Windows and Linux, each has its own top menu. Each menu documented below indicates which window type it is associated with.

Output windows, such as used for Edit => Find in Files, are a subtype of editor window. They currently have the same top menu but a different default title and context menu.

On macOS, there is one application menu. It dynamically changes according to the window currently selected. It has an IDLE menu, and some entries described below are moved around to conform to Apple guidelines.

File menu (Shell and Editor)
New File
Create a new file editing window.

Open…
Open an existing file with an Open dialog.

Open Module…
Open an existing module (searches sys.path).

Recent Files
Open a list of recent files. Click one to open it.

Module Browser
Show functions, classes, and methods in the current Editor file in a tree structure. In the shell, open a module first.

Path Browser
Show sys.path directories, modules, functions, classes and methods in a tree structure.

Save
Save the current window to the associated file, if there is one. Windows that have been changed since being opened or last saved have a * before and after the window title. If there is no associated file, do Save As instead.

Save As…
Save the current window with a Save As dialog. The file saved becomes the new associated file for the window. (If your file manager is set to hide extensions, the current extension will be omitted in the file name box. If the new filename has no ‘.’, ‘.py’ and ‘.txt’ will be added for Python and text files, except that on macOS Aqua,’.py’ is added for all files.)

Save Copy As…
Save the current window to different file without changing the associated file. (See Save As note above about filename extensions.)

Print Window
Print the current window to the default printer.

Close Window
Close the current window (if an unsaved editor, ask to save; if an unsaved Shell, ask to quit execution). Calling exit() or close() in the Shell window also closes Shell. If this is the only window, also exit IDLE.

Exit IDLE
Close all windows and quit IDLE (ask to save unsaved edit windows).

Edit menu (Shell and Editor)
Undo
Undo the last change to the current window. A maximum of 1000 changes may be undone.

Redo
Redo the last undone change to the current window.

Select All
Select the entire contents of the current window.

Cut
Copy selection into the system-wide clipboard; then delete the selection.

Copy
Copy selection into the system-wide clipboard.

Paste
Insert contents of the system-wide clipboard into the current window.

The clipboard functions are also available in context menus.

Find…
Open a search dialog with many options

Find Again
Repeat the last search, if there is one.

Find Selection
Search for the currently selected string, if there is one.

Find in Files…
Open a file search dialog. Put results in a new output window.

Replace…
Open a search-and-replace dialog.

Go to Line
Move the cursor to the beginning of the line requested and make that line visible. A request past the end of the file goes to the end. Clear any selection and update the line and column status.

Show Completions
Open a scrollable list allowing selection of existing names. See Completions in the Editing and navigation section below.

Expand Word
Expand a prefix you have typed to match a full word in the same window; repeat to get a different expansion.

Show Call Tip
After an unclosed parenthesis for a function, open a small window with function parameter hints. See Calltips in the Editing and navigation section below.

Show Surrounding Parens
Highlight the surrounding parenthesis.

Format menu (Editor window only)
Format Paragraph
Reformat the current blank-line-delimited paragraph in comment block or multiline string or selected line in a string. All lines in the paragraph will be formatted to less than N columns, where N defaults to 72.

Indent Region
Shift selected lines right by the indent width (default 4 spaces).

Dedent Region
Shift selected lines left by the indent width (default 4 spaces).

Comment Out Region
Insert ## in front of selected lines.

Uncomment Region
Remove leading # or ## from selected lines.

Tabify Region
Turn leading stretches of spaces into tabs. (Note: We recommend using 4 space blocks to indent Python code.)

Untabify Region
Turn all tabs into the correct number of spaces.

Toggle Tabs
Open a dialog to switch between indenting with spaces and tabs.

New Indent Width
Open a dialog to change indent width. The accepted default by the Python community is 4 spaces.

Strip Trailing Whitespace
Remove trailing space and other whitespace characters after the last non-whitespace character of a line by applying str.rstrip() to each line, including lines within multiline strings. Except for Shell windows, remove extra newlines at the end of the file.

Run menu (Editor window only)
Run Module
Do Check Module. If no error, restart the shell to clean the environment, then execute the module. Output is displayed in the Shell window. Note that output requires use of print or write. When execution is complete, the Shell retains focus and displays a prompt. At this point, one may interactively explore the result of execution. This is similar to executing a file with python -i file at a command line.

Run… Customized
Same as Run Module, but run the module with customized settings. Command Line Arguments extend sys.argv as if passed on a command line. The module can be run in the Shell without restarting.

Check Module
Check the syntax of the module currently open in the Editor window. If the module has not been saved IDLE will either prompt the user to save or autosave, as selected in the General tab of the Idle Settings dialog. If there is a syntax error, the approximate location is indicated in the Editor window.

Python Shell
Open or wake up the Python Shell window.

Shell menu (Shell window only)
View Last Restart
Scroll the shell window to the last Shell restart.

Restart Shell
Restart the shell to clean the environment and reset display and exception handling.

Previous History
Cycle through earlier commands in history which match the current entry.

Next History
Cycle through later commands in history which match the current entry.

Interrupt Execution
Stop a running program.

Debug menu (Shell window only)
Go to File/Line
Look on the current line. with the cursor, and the line above for a filename and line number. If found, open the file if not already open, and show the line. Use this to view source lines referenced in an exception traceback and lines found by Find in Files. Also available in the context menu of the Shell window and Output windows.

Debugger (toggle)
When activated, code entered in the Shell or run from an Editor will run under the debugger. In the Editor, breakpoints can be set with the context menu. This feature is still incomplete and somewhat experimental.

Stack Viewer
Show the stack traceback of the last exception in a tree widget, with access to locals and globals.

Auto-open Stack Viewer
Toggle automatically opening the stack viewer on an unhandled exception.

Options menu (Shell and Editor)
Configure IDLE
Open a configuration dialog and change preferences for the following: fonts, indentation, keybindings, text color themes, startup windows and size, additional help sources, and extensions. On macOS, open the configuration dialog by selecting Preferences in the application menu. For more details, see Setting preferences under Help and preferences.

Most configuration options apply to all windows or all future windows. The option items below only apply to the active window.

Show/Hide Code Context (Editor Window only)
Open a pane at the top of the edit window which shows the block context of the code which has scrolled above the top of the window. See Code Context in the Editing and Navigation section below.

Show/Hide Line Numbers (Editor Window only)
Open a column to the left of the edit window which shows the number of each line of text. The default is off, which may be changed in the preferences (see Setting preferences).

Zoom/Restore Height
Toggles the window between normal size and maximum height. The initial size defaults to 40 lines by 80 chars unless changed on the General tab of the Configure IDLE dialog. The maximum height for a screen is determined by momentarily maximizing a window the first time one is zoomed on the screen. Changing screen settings may invalidate the saved height. This toggle has no effect when a window is maximized.

Window menu (Shell and Editor)
Lists the names of all open windows; select one to bring it to the foreground (deiconifying it if necessary).

Help menu (Shell and Editor)
About IDLE
Display version, copyright, license, credits, and more.

IDLE Help
Display this IDLE document, detailing the menu options, basic editing and navigation, and other tips.

Python Docs
Access local Python documentation, if installed, or start a web browser and open docs.python.org showing the latest Python documentation.

Turtle Demo
Run the turtledemo module with example Python code and turtle drawings.

Additional help sources may be added here with the Configure IDLE dialog under the General tab. See the Help sources subsection below for more on Help menu choices.

Context menus
Open a context menu by right-clicking in a window (Control-click on macOS). Context menus have the standard clipboard functions also on the Edit menu.

Cut
Copy selection into the system-wide clipboard; then delete the selection.

Copy
Copy selection into the system-wide clipboard.

Paste
Insert contents of the system-wide clipboard into the current window.

Editor windows also have breakpoint functions. Lines with a breakpoint set are specially marked. Breakpoints only have an effect when running under the debugger. Breakpoints for a file are saved in the user’s .idlerc directory.

Set Breakpoint
Set a breakpoint on the current line.

Clear Breakpoint
Clear the breakpoint on that line.

Shell and Output windows also have the following.

Go to file/line
Same as in Debug menu.

The Shell window also has an output squeezing facility explained in the Python Shell window subsection below.

Squeeze
If the cursor is over an output line, squeeze all the output between the code above and the prompt below down to a ‘Squeezed text’ label.

Editing and Navigation
Editor windows
IDLE may open editor windows when it starts, depending on settings and how you start IDLE. Thereafter, use the File menu. There can be only one open editor window for a given file.

The title bar contains the name of the file, the full path, and the version of Python and IDLE running the window. The status bar contains the line number (‘Ln’) and column number (‘Col’). Line numbers start with 1; column numbers with 0.

IDLE assumes that files with a known .py* extension contain Python code and that other files do not. Run Python code with the Run menu.

Key bindings
The IDLE insertion cursor is a thin vertical bar between character positions. When characters are entered, the insertion cursor and everything to its right moves right one character and the new character is entered in the new space.

Several non-character keys move the cursor and possibly delete characters. Deletion does not puts text on the clipboard, but IDLE has an undo list. Wherever this doc discusses keys, ‘C’ refers to the Control key on Windows and Unix and the Command key on macOS. (And all such discussions assume that the keys have not been re-bound to something else.)

Arrow keys move the cursor one character or line.

C-LeftArrow and C-RightArrow moves left or right one word.

Home and End go to the beginning or end of the line.

Page Up and Page Down go up or down one screen.

C-Home and C-End go to beginning or end of the file.

Backspace and Del (or C-d) delete the previous or next character.

C-Backspace and C-Del delete one word left or right.

C-k deletes (‘kills’) everything to the right.

Standard keybindings (like C-c to copy and C-v to paste) may work. Keybindings are selected in the Configure IDLE dialog.

Automatic indentation
After a block-opening statement, the next line is indented by 4 spaces (in the Python Shell window by one tab). After certain keywords (break, return etc.) the next line is dedented. In leading indentation, Backspace deletes up to 4 spaces if they are there. Tab inserts spaces (in the Python Shell window one tab), number depends on Indent width. Currently, tabs are restricted to four spaces due to Tcl/Tk limitations.

See also the indent/dedent region commands on the Format menu.

Search and Replace
Any selection becomes a search target. However, only selections within a line work because searches are only performed within lines with the terminal newline removed. If [x] Regular expression is checked, the target is interpreted according to the Python re module.

Completions
Completions are supplied, when requested and available, for module names, attributes of classes or functions, or filenames. Each request method displays a completion box with existing names. (See tab completions below for an exception.) For any box, change the name being completed and the item highlighted in the box by typing and deleting characters; by hitting Up, Down, PageUp, PageDown, Home, and End keys; and by a single click within the box. Close the box with Escape, Enter, and double Tab keys or clicks outside the box. A double click within the box selects and closes.

One way to open a box is to type a key character and wait for a predefined interval. This defaults to 2 seconds; customize it in the settings dialog. (To prevent auto popups, set the delay to a large number of milliseconds, such as 100000000.) For imported module names or class or function attributes, type ‘.’. For filenames in the root directory, type os.sep or os.altsep immediately after an opening quote. (On Windows, one can specify a drive first.) Move into subdirectories by typing a directory name and a separator.

Instead of waiting, or after a box is closed, open a completion box immediately with Show Completions on the Edit menu. The default hot key is C-space. If one types a prefix for the desired name before opening the box, the first match or near miss is made visible. The result is the same as if one enters a prefix after the box is displayed. Show Completions after a quote completes filenames in the current directory instead of a root directory.

Hitting Tab after a prefix usually has the same effect as Show Completions. (With no prefix, it indents.) However, if there is only one match to the prefix, that match is immediately added to the editor text without opening a box.

Invoking ‘Show Completions’, or hitting Tab after a prefix, outside of a string and without a preceding ‘.’ opens a box with keywords, builtin names, and available module-level names.

When editing code in an editor (as oppose to Shell), increase the available module-level names by running your code and not restarting the Shell thereafter. This is especially useful after adding imports at the top of a file. This also increases possible attribute completions.

Completion boxes initially exclude names beginning with ‘_’ or, for modules, not included in ‘__all__’. The hidden names can be accessed by typing ‘_’ after ‘.’, either before or after the box is opened.

Calltips
A calltip is shown automatically when one types ( after the name of an accessible function. A function name expression may include dots and subscripts. A calltip remains until it is clicked, the cursor is moved out of the argument area, or ) is typed. Whenever the cursor is in the argument part of a definition, select Edit and “Show Call Tip” on the menu or enter its shortcut to display a calltip.

The calltip consists of the function’s signature and docstring up to the latter’s first blank line or the fifth non-blank line. (Some builtin functions lack an accessible signature.) A ‘/’ or ‘*’ in the signature indicates that the preceding or following arguments are passed by position or name (keyword) only. Details are subject to change.

In Shell, the accessible functions depends on what modules have been imported into the user process, including those imported by Idle itself, and which definitions have been run, all since the last restart.

For example, restart the Shell and enter itertools.count(. A calltip appears because Idle imports itertools into the user process for its own use. (This could change.) Enter turtle.write( and nothing appears. Idle does not itself import turtle. The menu entry and shortcut also do nothing. Enter import turtle. Thereafter, turtle.write( will display a calltip.

In an editor, import statements have no effect until one runs the file. One might want to run a file after writing import statements, after adding function definitions, or after opening an existing file.

Code Context
Within an editor window containing Python code, code context can be toggled in order to show or hide a pane at the top of the window. When shown, this pane freezes the opening lines for block code, such as those beginning with class, def, or if keywords, that would have otherwise scrolled out of view. The size of the pane will be expanded and contracted as needed to show the all current levels of context, up to the maximum number of lines defined in the Configure IDLE dialog (which defaults to 15). If there are no current context lines and the feature is toggled on, a single blank line will display. Clicking on a line in the context pane will move that line to the top of the editor.

The text and background colors for the context pane can be configured under the Highlights tab in the Configure IDLE dialog.

Shell window
In IDLE’s Shell, enter, edit, and recall complete statements. (Most consoles and terminals only work with a single physical line at a time).

Submit a single-line statement for execution by hitting Return with the cursor anywhere on the line. If a line is extended with Backslash (\), the cursor must be on the last physical line. Submit a multi-line compound statement by entering a blank line after the statement.

When one pastes code into Shell, it is not compiled and possibly executed until one hits Return, as specified above. One may edit pasted code first. If one pastes more than one statement into Shell, the result will be a SyntaxError when multiple statements are compiled as if they were one.

Lines containing RESTART mean that the user execution process has been re-started. This occurs when the user execution process has crashed, when one requests a restart on the Shell menu, or when one runs code in an editor window.

The editing features described in previous subsections work when entering code interactively. IDLE’s Shell window also responds to the following:

C-c attempts to interrupt statement execution (but may fail).

C-d closes Shell if typed at a >>> prompt.

Alt-p and Alt-n (C-p and C-n on macOS) retrieve to the current prompt the previous or next previously entered statement that matches anything already typed.

Return while the cursor is on any previous statement appends the latter to anything already typed at the prompt.

Text colors
Idle defaults to black on white text, but colors text with special meanings. For the shell, these are shell output, shell error, user output, and user error. For Python code, at the shell prompt or in an editor, these are keywords, builtin class and function names, names following class and def, strings, and comments. For any text window, these are the cursor (when present), found text (when possible), and selected text.

IDLE also highlights the soft keywords match, case, and _ in pattern-matching statements. However, this highlighting is not perfect and will be incorrect in some rare cases, including some _-s in case patterns.

Text coloring is done in the background, so uncolorized text is occasionally visible. To change the color scheme, use the Configure IDLE dialog Highlighting tab. The marking of debugger breakpoint lines in the editor and text in popups and dialogs is not user-configurable.

Startup and Code Execution
Upon startup with the -s option, IDLE will execute the file referenced by the environment variables IDLESTARTUP or PYTHONSTARTUP. IDLE first checks for IDLESTARTUP; if IDLESTARTUP is present the file referenced is run. If IDLESTARTUP is not present, IDLE checks for PYTHONSTARTUP. Files referenced by these environment variables are convenient places to store functions that are used frequently from the IDLE shell, or for executing import statements to import common modules.

In addition, Tk also loads a startup file if it is present. Note that the Tk file is loaded unconditionally. This additional file is .Idle.py and is looked for in the user’s home directory. Statements in this file will be executed in the Tk namespace, so this file is not useful for importing functions to be used from IDLE’s Python shell.

Command-line usage
IDLE can be invoked from the command line with various options. The general syntax is:

python -m idlelib [options] [file ...]
The following options are available:

-c <command>
Run the specified Python command in the shell window. For example, pass -c ""print('Hello, World!')"". On Windows, the outer quotes must be double quotes as shown.

-d
Enable the debugger and open the shell window.

-e
Open an editor window.

-h
Print a help message with legal combinations of options and exit.

-i
Open a shell window.

-r <file>
Run the specified file in the shell window.

-s
Run the startup file (as defined by the environment variables IDLESTARTUP or PYTHONSTARTUP) before opening the shell window.

-t <title>
Set the title of the shell window.

-
Read and execute standard input in the shell window. This option must be the last one before any arguments.

If arguments are provided:

If -, -c, or -r is used, all arguments are placed in sys.argv[1:], and sys.argv[0] is set to '', '-c', or '-r' respectively. No editor window is opened, even if that is the default set in the Options dialog.

Otherwise, arguments are treated as files to be opened for editing, and sys.argv reflects the arguments passed to IDLE itself.

Startup failure
IDLE uses a socket to communicate between the IDLE GUI process and the user code execution process. A connection must be established whenever the Shell starts or restarts. (The latter is indicated by a divider line that says ‘RESTART’). If the user process fails to connect to the GUI process, it usually displays a Tk error box with a ‘cannot connect’ message that directs the user here. It then exits.

One specific connection failure on Unix systems results from misconfigured masquerading rules somewhere in a system’s network setup. When IDLE is started from a terminal, one will see a message starting with ** Invalid host:. The valid value is 127.0.0.1 (idlelib.rpc.LOCALHOST). One can diagnose with tcpconnect -irv 127.0.0.1 6543 in one terminal window and tcplisten <same args> in another.

A common cause of failure is a user-written file with the same name as a standard library module, such as random.py and tkinter.py. When such a file is located in the same directory as a file that is about to be run, IDLE cannot import the stdlib file. The current fix is to rename the user file.

Though less common than in the past, an antivirus or firewall program may stop the connection. If the program cannot be taught to allow the connection, then it must be turned off for IDLE to work. It is safe to allow this internal connection because no data is visible on external ports. A similar problem is a network mis-configuration that blocks connections.

Python installation issues occasionally stop IDLE: multiple versions can clash, or a single installation might need admin access. If one undo the clash, or cannot or does not want to run as admin, it might be easiest to completely remove Python and start over.

A zombie pythonw.exe process could be a problem. On Windows, use Task Manager to check for one and stop it if there is. Sometimes a restart initiated by a program crash or Keyboard Interrupt (control-C) may fail to connect. Dismissing the error box or using Restart Shell on the Shell menu may fix a temporary problem.

When IDLE first starts, it attempts to read user configuration files in ~/.idlerc/ (~ is one’s home directory). If there is a problem, an error message should be displayed. Leaving aside random disk glitches, this can be prevented by never editing the files by hand. Instead, use the configuration dialog, under Options. Once there is an error in a user configuration file, the best solution may be to delete it and start over with the settings dialog.

If IDLE quits with no message, and it was not started from a console, try starting it from a console or terminal (python -m idlelib) and see if this results in an error message.

On Unix-based systems with tcl/tk older than 8.6.11 (see About IDLE) certain characters of certain fonts can cause a tk failure with a message to the terminal. This can happen either if one starts IDLE to edit a file with such a character or later when entering such a character. If one cannot upgrade tcl/tk, then re-configure IDLE to use a font that works better.

Running user code
With rare exceptions, the result of executing Python code with IDLE is intended to be the same as executing the same code by the default method, directly with Python in a text-mode system console or terminal window. However, the different interface and operation occasionally affect visible results. For instance, sys.modules starts with more entries, and threading.active_count() returns 2 instead of 1.

By default, IDLE runs user code in a separate OS process rather than in the user interface process that runs the shell and editor. In the execution process, it replaces sys.stdin, sys.stdout, and sys.stderr with objects that get input from and send output to the Shell window. The original values stored in sys.__stdin__, sys.__stdout__, and sys.__stderr__ are not touched, but may be None.

Sending print output from one process to a text widget in another is slower than printing to a system terminal in the same process. This has the most effect when printing multiple arguments, as the string for each argument, each separator, the newline are sent separately. For development, this is usually not a problem, but if one wants to print faster in IDLE, format and join together everything one wants displayed together and then print a single string. Both format strings and str.join() can help combine fields and lines.

IDLE’s standard stream replacements are not inherited by subprocesses created in the execution process, whether directly by user code or by modules such as multiprocessing. If such subprocess use input from sys.stdin or print or write to sys.stdout or sys.stderr, IDLE should be started in a command line window. (On Windows, use python or py rather than pythonw or pyw.) The secondary subprocess will then be attached to that window for input and output.

If sys is reset by user code, such as with importlib.reload(sys), IDLE’s changes are lost and input from the keyboard and output to the screen will not work correctly.

When Shell has the focus, it controls the keyboard and screen. This is normally transparent, but functions that directly access the keyboard and screen will not work. These include system-specific functions that determine whether a key has been pressed and if so, which.

The IDLE code running in the execution process adds frames to the call stack that would not be there otherwise. IDLE wraps sys.getrecursionlimit and sys.setrecursionlimit to reduce the effect of the additional stack frames.

When user code raises SystemExit either directly or by calling sys.exit, IDLE returns to a Shell prompt instead of exiting.

User output in Shell
When a program outputs text, the result is determined by the corresponding output device. When IDLE executes user code, sys.stdout and sys.stderr are connected to the display area of IDLE’s Shell. Some of its features are inherited from the underlying Tk Text widget. Others are programmed additions. Where it matters, Shell is designed for development rather than production runs.

For instance, Shell never throws away output. A program that sends unlimited output to Shell will eventually fill memory, resulting in a memory error. In contrast, some system text windows only keep the last n lines of output. A Windows console, for instance, keeps a user-settable 1 to 9999 lines, with 300 the default.

A Tk Text widget, and hence IDLE’s Shell, displays characters (codepoints) in the BMP (Basic Multilingual Plane) subset of Unicode. Which characters are displayed with a proper glyph and which with a replacement box depends on the operating system and installed fonts. Tab characters cause the following text to begin after the next tab stop. (They occur every 8 ‘characters’). Newline characters cause following text to appear on a new line. Other control characters are ignored or displayed as a space, box, or something else, depending on the operating system and font. (Moving the text cursor through such output with arrow keys may exhibit some surprising spacing behavior.)

s = 'a\tb\a<\x02><\r>\bc\nd'  # Enter 22 chars.
len(s)
14
s  # Display repr(s)
'a\tb\x07<\x02><\r>\x08c\nd'
print(s, end='')  # Display s as is.
# Result varies by OS and font.  Try it.
The repr function is used for interactive echo of expression values. It returns an altered version of the input string in which control codes, some BMP codepoints, and all non-BMP codepoints are replaced with escape codes. As demonstrated above, it allows one to identify the characters in a string, regardless of how they are displayed.

Normal and error output are generally kept separate (on separate lines) from code input and each other. They each get different highlight colors.

For SyntaxError tracebacks, the normal ‘^’ marking where the error was detected is replaced by coloring the text with an error highlight. When code run from a file causes other exceptions, one may right click on a traceback line to jump to the corresponding line in an IDLE editor. The file will be opened if necessary.

Shell has a special facility for squeezing output lines down to a ‘Squeezed text’ label. This is done automatically for output over N lines (N = 50 by default). N can be changed in the PyShell section of the General page of the Settings dialog. Output with fewer lines can be squeezed by right clicking on the output. This can be useful lines long enough to slow down scrolling.

Squeezed output is expanded in place by double-clicking the label. It can also be sent to the clipboard or a separate view window by right-clicking the label.

Developing tkinter applications
IDLE is intentionally different from standard Python in order to facilitate development of tkinter programs. Enter import tkinter as tk; root = tk.Tk() in standard Python and nothing appears. Enter the same in IDLE and a tk window appears. In standard Python, one must also enter root.update() to see the window. IDLE does the equivalent in the background, about 20 times a second, which is about every 50 milliseconds. Next enter b = tk.Button(root, text='button'); b.pack(). Again, nothing visibly changes in standard Python until one enters root.update().

Most tkinter programs run root.mainloop(), which usually does not return until the tk app is destroyed. If the program is run with python -i or from an IDLE editor, a >>> shell prompt does not appear until mainloop() returns, at which time there is nothing left to interact with.

When running a tkinter program from an IDLE editor, one can comment out the mainloop call. One then gets a shell prompt immediately and can interact with the live application. One just has to remember to re-enable the mainloop call when running in standard Python.

Running without a subprocess
By default, IDLE executes user code in a separate subprocess via a socket, which uses the internal loopback interface. This connection is not externally visible and no data is sent to or received from the internet. If firewall software complains anyway, you can ignore it.

If the attempt to make the socket connection fails, Idle will notify you. Such failures are sometimes transient, but if persistent, the problem may be either a firewall blocking the connection or misconfiguration of a particular system. Until the problem is fixed, one can run Idle with the -n command line switch.

If IDLE is started with the -n command line switch it will run in a single process and will not create the subprocess which runs the RPC Python execution server. This can be useful if Python cannot create the subprocess or the RPC socket interface on your platform. However, in this mode user code is not isolated from IDLE itself. Also, the environment is not restarted when Run/Run Module (F5) is selected. If your code has been modified, you must reload() the affected modules and re-import any specific items (e.g. from foo import baz) if the changes are to take effect. For these reasons, it is preferable to run IDLE with the default subprocess if at all possible.

Deprecated since version 3.4.

Help and Preferences
Help sources
Help menu entry “IDLE Help” displays a formatted html version of the IDLE chapter of the Library Reference. The result, in a read-only tkinter text window, is close to what one sees in a web browser. Navigate through the text with a mousewheel, the scrollbar, or up and down arrow keys held down. Or click the TOC (Table of Contents) button and select a section header in the opened box.

Help menu entry “Python Docs” opens the extensive sources of help, including tutorials, available at docs.python.org/x.y, where ‘x.y’ is the currently running Python version. If your system has an off-line copy of the docs (this may be an installation option), that will be opened instead.

Selected URLs can be added or removed from the help menu at any time using the General tab of the Configure IDLE dialog.

Setting preferences
The font preferences, highlighting, keys, and general preferences can be changed via Configure IDLE on the Option menu. Non-default user settings are saved in a .idlerc directory in the user’s home directory. Problems caused by bad user configuration files are solved by editing or deleting one or more of the files in .idlerc.

On the Font tab, see the text sample for the effect of font face and size on multiple characters in multiple languages. Edit the sample to add other characters of personal interest. Use the sample to select monospaced fonts. If particular characters have problems in Shell or an editor, add them to the top of the sample and try changing first size and then font.

On the Highlights and Keys tab, select a built-in or custom color theme and key set. To use a newer built-in color theme or key set with older IDLEs, save it as a new custom theme or key set and it well be accessible to older IDLEs.

IDLE on macOS
Under System Preferences: Dock, one can set “Prefer tabs when opening documents” to “Always”. This setting is not compatible with the tk/tkinter GUI framework used by IDLE, and it breaks a few IDLE features.

Extensions
IDLE contains an extension facility. Preferences for extensions can be changed with the Extensions tab of the preferences dialog. See the beginning of config-extensions.def in the idlelib directory for further information. The only current default extension is zzdummy, an example also used for testing.

idlelib — implementation of IDLE application
Source code: Lib/idlelib

The Lib/idlelib package implements the IDLE application. See the rest of this page for how to use IDLE.

The files in idlelib are described in idlelib/README.txt. Access it either in idlelib or click Help => About IDLE on the IDLE menu. This file also maps IDLE menu items to the code that implements the item. Except for files listed under ‘Startup’, the idlelib code is ‘private’ in sense that feature changes can be backported (see PEP 434)."
"Python_ip_adress_introduction","Docmentation","Priority","3.14","Python, IPs, Module, Firewall","An introduction to the ipaddress module
author:
Peter Moody

author:
Nick Coghlan

Overview

This document aims to provide a gentle introduction to the ipaddress module. It is aimed primarily at users that aren’t already familiar with IP networking terminology, but may also be useful to network engineers wanting an overview of how ipaddress represents IP network addressing concepts.

Creating Address/Network/Interface objects
Since ipaddress is a module for inspecting and manipulating IP addresses, the first thing you’ll want to do is create some objects. You can use ipaddress to create objects from strings and integers.

A Note on IP Versions
For readers that aren’t particularly familiar with IP addressing, it’s important to know that the Internet Protocol (IP) is currently in the process of moving from version 4 of the protocol to version 6. This transition is occurring largely because version 4 of the protocol doesn’t provide enough addresses to handle the needs of the whole world, especially given the increasing number of devices with direct connections to the internet.

Explaining the details of the differences between the two versions of the protocol is beyond the scope of this introduction, but readers need to at least be aware that these two versions exist, and it will sometimes be necessary to force the use of one version or the other.

IP Host Addresses
Addresses, often referred to as “host addresses” are the most basic unit when working with IP addressing. The simplest way to create addresses is to use the ipaddress.ip_address() factory function, which automatically determines whether to create an IPv4 or IPv6 address based on the passed in value:

ipaddress.ip_address('192.0.2.1')
IPv4Address('192.0.2.1')
ipaddress.ip_address('2001:DB8::1')
IPv6Address('2001:db8::1')
Addresses can also be created directly from integers. Values that will fit within 32 bits are assumed to be IPv4 addresses:

ipaddress.ip_address(3221225985)
IPv4Address('192.0.2.1')
ipaddress.ip_address(42540766411282592856903984951653826561)
IPv6Address('2001:db8::1')
To force the use of IPv4 or IPv6 addresses, the relevant classes can be invoked directly. This is particularly useful to force creation of IPv6 addresses for small integers:

ipaddress.ip_address(1)
IPv4Address('0.0.0.1')
ipaddress.IPv4Address(1)
IPv4Address('0.0.0.1')
ipaddress.IPv6Address(1)
IPv6Address('::1')
Defining Networks
Host addresses are usually grouped together into IP networks, so ipaddress provides a way to create, inspect and manipulate network definitions. IP network objects are constructed from strings that define the range of host addresses that are part of that network. The simplest form for that information is a “network address/network prefix” pair, where the prefix defines the number of leading bits that are compared to determine whether or not an address is part of the network and the network address defines the expected value of those bits.

As for addresses, a factory function is provided that determines the correct IP version automatically:

ipaddress.ip_network('192.0.2.0/24')
IPv4Network('192.0.2.0/24')
ipaddress.ip_network('2001:db8::0/96')
IPv6Network('2001:db8::/96')
Network objects cannot have any host bits set. The practical effect of this is that 192.0.2.1/24 does not describe a network. Such definitions are referred to as interface objects since the ip-on-a-network notation is commonly used to describe network interfaces of a computer on a given network and are described further in the next section.

By default, attempting to create a network object with host bits set will result in ValueError being raised. To request that the additional bits instead be coerced to zero, the flag strict=False can be passed to the constructor:

ipaddress.ip_network('192.0.2.1/24')
Traceback (most recent call last):
   ...
ValueError: 192.0.2.1/24 has host bits set
ipaddress.ip_network('192.0.2.1/24', strict=False)
IPv4Network('192.0.2.0/24')
While the string form offers significantly more flexibility, networks can also be defined with integers, just like host addresses. In this case, the network is considered to contain only the single address identified by the integer, so the network prefix includes the entire network address:

ipaddress.ip_network(3221225984)
IPv4Network('192.0.2.0/32')
ipaddress.ip_network(42540766411282592856903984951653826560)
IPv6Network('2001:db8::/128')
As with addresses, creation of a particular kind of network can be forced by calling the class constructor directly instead of using the factory function.

Host Interfaces
As mentioned just above, if you need to describe an address on a particular network, neither the address nor the network classes are sufficient. Notation like 192.0.2.1/24 is commonly used by network engineers and the people who write tools for firewalls and routers as shorthand for “the host 192.0.2.1 on the network 192.0.2.0/24”, Accordingly, ipaddress provides a set of hybrid classes that associate an address with a particular network. The interface for creation is identical to that for defining network objects, except that the address portion isn’t constrained to being a network address.

ipaddress.ip_interface('192.0.2.1/24')
IPv4Interface('192.0.2.1/24')
ipaddress.ip_interface('2001:db8::1/96')
IPv6Interface('2001:db8::1/96')
Integer inputs are accepted (as with networks), and use of a particular IP version can be forced by calling the relevant constructor directly.

Inspecting Address/Network/Interface Objects
You’ve gone to the trouble of creating an IPv(4|6)(Address|Network|Interface) object, so you probably want to get information about it. ipaddress tries to make doing this easy and intuitive.

Extracting the IP version:

addr4 = ipaddress.ip_address('192.0.2.1')
addr6 = ipaddress.ip_address('2001:db8::1')
addr6.version
6
addr4.version
4
Obtaining the network from an interface:

host4 = ipaddress.ip_interface('192.0.2.1/24')
host4.network
IPv4Network('192.0.2.0/24')
host6 = ipaddress.ip_interface('2001:db8::1/96')
host6.network
IPv6Network('2001:db8::/96')
Finding out how many individual addresses are in a network:

net4 = ipaddress.ip_network('192.0.2.0/24')
net4.num_addresses
256
net6 = ipaddress.ip_network('2001:db8::0/96')
net6.num_addresses
4294967296
Iterating through the “usable” addresses on a network:

net4 = ipaddress.ip_network('192.0.2.0/24')
for x in net4.hosts():
    print(x)
192.0.2.1
192.0.2.2
192.0.2.3
192.0.2.4
...
192.0.2.252
192.0.2.253
192.0.2.254
Obtaining the netmask (i.e. set bits corresponding to the network prefix) or the hostmask (any bits that are not part of the netmask):

net4 = ipaddress.ip_network('192.0.2.0/24')
net4.netmask
IPv4Address('255.255.255.0')
net4.hostmask
IPv4Address('0.0.0.255')
net6 = ipaddress.ip_network('2001:db8::0/96')
net6.netmask
IPv6Address('ffff:ffff:ffff:ffff:ffff:ffff::')
net6.hostmask
IPv6Address('::ffff:ffff')
Exploding or compressing the address:

addr6.exploded
'2001:0db8:0000:0000:0000:0000:0000:0001'
addr6.compressed
'2001:db8::1'
net6.exploded
'2001:0db8:0000:0000:0000:0000:0000:0000/96'
net6.compressed
'2001:db8::/96'
While IPv4 doesn’t support explosion or compression, the associated objects still provide the relevant properties so that version neutral code can easily ensure the most concise or most verbose form is used for IPv6 addresses while still correctly handling IPv4 addresses.

Networks as lists of Addresses
It’s sometimes useful to treat networks as lists. This means it is possible to index them like this:

net4[1]
IPv4Address('192.0.2.1')
net4[-1]
IPv4Address('192.0.2.255')
net6[1]
IPv6Address('2001:db8::1')
net6[-1]
IPv6Address('2001:db8::ffff:ffff')
It also means that network objects lend themselves to using the list membership test syntax like this:

if address in network:
    # do something
Containment testing is done efficiently based on the network prefix:

addr4 = ipaddress.ip_address('192.0.2.1')
addr4 in ipaddress.ip_network('192.0.2.0/24')
True
addr4 in ipaddress.ip_network('192.0.3.0/24')
False
Comparisons
ipaddress provides some simple, hopefully intuitive ways to compare objects, where it makes sense:

ipaddress.ip_address('192.0.2.1') < ipaddress.ip_address('192.0.2.2')
True
A TypeError exception is raised if you try to compare objects of different versions or different types.

Using IP Addresses with other modules
Other modules that use IP addresses (such as socket) usually won’t accept objects from this module directly. Instead, they must be coerced to an integer or string that the other module will accept:

addr4 = ipaddress.ip_address('192.0.2.1')
str(addr4)
'192.0.2.1'
int(addr4)
3221225985
Getting more detail when instance creation fails
When creating address/network/interface objects using the version-agnostic factory functions, any errors will be reported as ValueError with a generic error message that simply says the passed in value was not recognized as an object of that type. The lack of a specific error is because it’s necessary to know whether the value is supposed to be IPv4 or IPv6 in order to provide more detail on why it has been rejected.

To support use cases where it is useful to have access to this additional detail, the individual class constructors actually raise the ValueError subclasses ipaddress.AddressValueError and ipaddress.NetmaskValueError to indicate exactly which part of the definition failed to parse correctly.

The error messages are significantly more detailed when using the class constructors directly. For example:

ipaddress.ip_address(""192.168.0.256"")
Traceback (most recent call last):
  ...
ValueError: '192.168.0.256' does not appear to be an IPv4 or IPv6 address
ipaddress.IPv4Address(""192.168.0.256"")
Traceback (most recent call last):
  ...
ipaddress.AddressValueError: Octet 256 (> 255) not permitted in '192.168.0.256'

ipaddress.ip_network(""192.168.0.1/64"")
Traceback (most recent call last):
  ...
ValueError: '192.168.0.1/64' does not appear to be an IPv4 or IPv6 network
ipaddress.IPv4Network(""192.168.0.1/64"")
Traceback (most recent call last):
  ...
ipaddress.NetmaskValueError: '64' is not a valid netmask
However, both of the module specific exceptions have ValueError as their parent class, so if you’re not concerned with the particular type of error, you can still write code like the following:

try:
    network = ipaddress.IPv4Network(address)
except ValueError:
    print('address/netmask is invalid for IPv4:', address)"
"Python_ftplib_FTP_protocol_client","Documentation","High","3.14","Python, Firewall, FTP","ftplib — FTP protocol client
Source code: Lib/ftplib.py

This module defines the class FTP and a few related items. The FTP class implements the client side of the FTP protocol. You can use this to write Python programs that perform a variety of automated FTP jobs, such as mirroring other FTP servers. It is also used by the module urllib.request to handle URLs that use FTP. For more information on FTP (File Transfer Protocol), see internet RFC 959.

The default encoding is UTF-8, following RFC 2640.

Availability: not WASI.

This module does not work or is not available on WebAssembly. See WebAssembly platforms for more information.

Here’s a sample session using the ftplib module:

from ftplib import FTP
ftp = FTP('ftp.us.debian.org')  # connect to host, default port
ftp.login()                     # user anonymous, passwd anonymous@
'230 Login successful.'
ftp.cwd('debian')               # change into ""debian"" directory
'250 Directory successfully changed.'
ftp.retrlines('LIST')           # list directory contents
-rw-rw-r--    1 1176     1176         1063 Jun 15 10:18 README
...
drwxr-sr-x    5 1176     1176         4096 Dec 19  2000 pool
drwxr-sr-x    4 1176     1176         4096 Nov 17  2008 project
drwxr-xr-x    3 1176     1176         4096 Oct 10  2012 tools
'226 Directory send OK.'
with open('README', 'wb') as fp:
    ftp.retrbinary('RETR README', fp.write)
'226 Transfer complete.'
ftp.quit()
'221 Goodbye.'
Reference
FTP objects
class ftplib.FTP(host='', user='', passwd='', acct='', timeout=None, source_address=None, *, encoding='utf-8')
Return a new instance of the FTP class.

Parameters:
host (str) – The hostname to connect to. If given, connect(host) is implicitly called by the constructor.

user (str) – The username to log in with (default: 'anonymous'). If given, login(host, passwd, acct) is implicitly called by the constructor.

passwd (str) – The password to use when logging in. If not given, and if passwd is the empty string or ""-"", a password will be automatically generated.

acct (str) – Account information to be used for the ACCT FTP command. Few systems implement this. See RFC-959 for more details.

timeout (float | None) – A timeout in seconds for blocking operations like connect() (default: the global default timeout setting).

source_address (tuple | None) – A 2-tuple (host, port) for the socket to bind to as its source address before connecting.

encoding (str) – The encoding for directories and filenames (default: 'utf-8').

The FTP class supports the with statement, e.g.:

from ftplib import FTP
with FTP(""ftp1.at.proftpd.org"") as ftp:
    ftp.login()
    ftp.dir()

'230 Anonymous login ok, restrictions apply.'
dr-xr-xr-x   9 ftp      ftp           154 May  6 10:43 .
dr-xr-xr-x   9 ftp      ftp           154 May  6 10:43 ..
dr-xr-xr-x   5 ftp      ftp          4096 May  6 10:43 CentOS
dr-xr-xr-x   3 ftp      ftp            18 Jul 10  2008 Fedora

Changed in version 3.2: Support for the with statement was added.

Changed in version 3.3: source_address parameter was added.

Changed in version 3.9: If the timeout parameter is set to be zero, it will raise a ValueError to prevent the creation of a non-blocking socket. The encoding parameter was added, and the default was changed from Latin-1 to UTF-8 to follow RFC 2640.

Several FTP methods are available in two flavors: one for handling text files and another for binary files. The methods are named for the command which is used followed by lines for the text version or binary for the binary version.

FTP instances have the following methods:

set_debuglevel(level)
Set the instance’s debugging level as an int. This controls the amount of debugging output printed. The debug levels are:

0 (default): No debug output.

1: Produce a moderate amount of debug output, generally a single line per request.

2 or higher: Produce the maximum amount of debugging output, logging each line sent and received on the control connection.

connect(host='', port=0, timeout=None, source_address=None)
Connect to the given host and port. This function should be called only once for each instance; it should not be called if a host argument was given when the FTP instance was created. All other FTP methods can only be called after a connection has successfully been made.

Parameters:
host (str) – The host to connect to.

port (int) – The TCP port to connect to (default: 21, as specified by the FTP protocol specification). It is rarely needed to specify a different port number.

timeout (float | None) – A timeout in seconds for the connection attempt (default: the global default timeout setting).

source_address (tuple | None) – A 2-tuple (host, port) for the socket to bind to as its source address before connecting.

Raises an auditing event ftplib.connect with arguments self, host, port.

Changed in version 3.3: source_address parameter was added.

getwelcome()
Return the welcome message sent by the server in reply to the initial connection. (This message sometimes contains disclaimers or help information that may be relevant to the user.)

login(user='anonymous', passwd='', acct='')
Log on to the connected FTP server. This function should be called only once for each instance, after a connection has been established; it should not be called if the host and user arguments were given when the FTP instance was created. Most FTP commands are only allowed after the client has logged in.

Parameters:
user (str) – The username to log in with (default: 'anonymous').

passwd (str) – The password to use when logging in. If not given, and if passwd is the empty string or ""-"", a password will be automatically generated.

acct (str) – Account information to be used for the ACCT FTP command. Few systems implement this. See RFC-959 for more details.

abort()
Abort a file transfer that is in progress. Using this does not always work, but it’s worth a try.

sendcmd(cmd)
Send a simple command string to the server and return the response string.

Raises an auditing event ftplib.sendcmd with arguments self, cmd.

voidcmd(cmd)
Send a simple command string to the server and handle the response. Return the response string if the response code corresponds to success (codes in the range 200–299). Raise error_reply otherwise.

Raises an auditing event ftplib.sendcmd with arguments self, cmd.

retrbinary(cmd, callback, blocksize=8192, rest=None)
Retrieve a file in binary transfer mode.

Parameters:
cmd (str) – An appropriate RETR command: ""RETR filename"".

callback (callable) – A single parameter callable that is called for each block of data received, with its single argument being the data as bytes.

blocksize (int) – The maximum chunk size to read on the low-level socket object created to do the actual transfer. This also corresponds to the largest size of data that will be passed to callback. Defaults to 8192.

rest (int) – A REST command to be sent to the server. See the documentation for the rest parameter of the transfercmd() method.

retrlines(cmd, callback=None)
Retrieve a file or directory listing in the encoding specified by the encoding parameter at initialization. cmd should be an appropriate RETR command (see retrbinary()) or a command such as LIST or NLST (usually just the string 'LIST'). LIST retrieves a list of files and information about those files. NLST retrieves a list of file names. The callback function is called for each line with a string argument containing the line with the trailing CRLF stripped. The default callback prints the line to sys.stdout.

set_pasv(val)
Enable “passive” mode if val is true, otherwise disable passive mode. Passive mode is on by default.

storbinary(cmd, fp, blocksize=8192, callback=None, rest=None)
Store a file in binary transfer mode.

Parameters:
cmd (str) – An appropriate STOR command: ""STOR filename"".

fp (file object) – A file object (opened in binary mode) which is read until EOF, using its read() method in blocks of size blocksize to provide the data to be stored.

blocksize (int) – The read block size. Defaults to 8192.

callback (callable) – A single parameter callable that is called for each block of data sent, with its single argument being the data as bytes.

rest (int) – A REST command to be sent to the server. See the documentation for the rest parameter of the transfercmd() method.

Changed in version 3.2: The rest parameter was added.

storlines(cmd, fp, callback=None)
Store a file in line mode. cmd should be an appropriate STOR command (see storbinary()). Lines are read until EOF from the file object fp (opened in binary mode) using its readline() method to provide the data to be stored. callback is an optional single parameter callable that is called on each line after it is sent.

transfercmd(cmd, rest=None)
Initiate a transfer over the data connection. If the transfer is active, send an EPRT or PORT command and the transfer command specified by cmd, and accept the connection. If the server is passive, send an EPSV or PASV command, connect to it, and start the transfer command. Either way, return the socket for the connection.

If optional rest is given, a REST command is sent to the server, passing rest as an argument. rest is usually a byte offset into the requested file, telling the server to restart sending the file’s bytes at the requested offset, skipping over the initial bytes. Note however that the transfercmd() method converts rest to a string with the encoding parameter specified at initialization, but no check is performed on the string’s contents. If the server does not recognize the REST command, an error_reply exception will be raised. If this happens, simply call transfercmd() without a rest argument.

ntransfercmd(cmd, rest=None)
Like transfercmd(), but returns a tuple of the data connection and the expected size of the data. If the expected size could not be computed, None will be returned as the expected size. cmd and rest means the same thing as in transfercmd().

mlsd(path='', facts=[])
List a directory in a standardized format by using MLSD command (RFC 3659). If path is omitted the current directory is assumed. facts is a list of strings representing the type of information desired (e.g. [""type"", ""size"", ""perm""]). Return a generator object yielding a tuple of two elements for every file found in path. First element is the file name, the second one is a dictionary containing facts about the file name. Content of this dictionary might be limited by the facts argument but server is not guaranteed to return all requested facts.

Added in version 3.3.

nlst(argument[, ...])
Return a list of file names as returned by the NLST command. The optional argument is a directory to list (default is the current server directory). Multiple arguments can be used to pass non-standard options to the NLST command.

Note If your server supports the command, mlsd() offers a better API.
dir(argument[, ...])
Produce a directory listing as returned by the LIST command, printing it to standard output. The optional argument is a directory to list (default is the current server directory). Multiple arguments can be used to pass non-standard options to the LIST command. If the last argument is a function, it is used as a callback function as for retrlines(); the default prints to sys.stdout. This method returns None.

Note If your server supports the command, mlsd() offers a better API.
rename(fromname, toname)
Rename file fromname on the server to toname.

delete(filename)
Remove the file named filename from the server. If successful, returns the text of the response, otherwise raises error_perm on permission errors or error_reply on other errors.

cwd(pathname)
Set the current directory on the server.

mkd(pathname)
Create a new directory on the server.

pwd()
Return the pathname of the current directory on the server.

rmd(dirname)
Remove the directory named dirname on the server.

size(filename)
Request the size of the file named filename on the server. On success, the size of the file is returned as an integer, otherwise None is returned. Note that the SIZE command is not standardized, but is supported by many common server implementations.

quit()
Send a QUIT command to the server and close the connection. This is the “polite” way to close a connection, but it may raise an exception if the server responds with an error to the QUIT command. This implies a call to the close() method which renders the FTP instance useless for subsequent calls (see below).

close()
Close the connection unilaterally. This should not be applied to an already closed connection such as after a successful call to quit(). After this call the FTP instance should not be used any more (after a call to close() or quit() you cannot reopen the connection by issuing another login() method).

FTP_TLS objects
class ftplib.FTP_TLS(host='', user='', passwd='', acct='', *, context=None, timeout=None, source_address=None, encoding='utf-8')
An FTP subclass which adds TLS support to FTP as described in RFC 4217. Connect to port 21 implicitly securing the FTP control connection before authenticating.

Note The user must explicitly secure the data connection by calling the prot_p() method.
Parameters:
host (str) – The hostname to connect to. If given, connect(host) is implicitly called by the constructor.

user (str) – The username to log in with (default: 'anonymous'). If given, login(host, passwd, acct) is implicitly called by the constructor.

passwd (str) – The password to use when logging in. If not given, and if passwd is the empty string or ""-"", a password will be automatically generated.

acct (str) – Account information to be used for the ACCT FTP command. Few systems implement this. See RFC-959 for more details.

context (ssl.SSLContext) – An SSL context object which allows bundling SSL configuration options, certificates and private keys into a single, potentially long-lived, structure. Please read Security considerations for best practices.

timeout (float | None) – A timeout in seconds for blocking operations like connect() (default: the global default timeout setting).

source_address (tuple | None) – A 2-tuple (host, port) for the socket to bind to as its source address before connecting.

encoding (str) – The encoding for directories and filenames (default: 'utf-8').

Added in version 3.2.

Changed in version 3.3: Added the source_address parameter.

Changed in version 3.4: The class now supports hostname check with ssl.SSLContext.check_hostname and Server Name Indication (see ssl.HAS_SNI).

Changed in version 3.9: If the timeout parameter is set to be zero, it will raise a ValueError to prevent the creation of a non-blocking socket. The encoding parameter was added, and the default was changed from Latin-1 to UTF-8 to follow RFC 2640.

Changed in version 3.12: The deprecated keyfile and certfile parameters have been removed.

Here’s a sample session using the FTP_TLS class:

ftps = FTP_TLS('ftp.pureftpd.org')
ftps.login()
'230 Anonymous user logged in'
ftps.prot_p()
'200 Data protection level set to ""private""'
ftps.nlst()
['6jack', 'OpenBSD', 'antilink', 'blogbench', 'bsdcam', 'clockspeed', 'djbdns-jedi', 'docs', 'eaccelerator-jedi', 'favicon.ico', 'francotone', 'fugu', 'ignore', 'libpuzzle', 'metalog', 'minidentd', 'misc', 'mysql-udf-global-user-variables', 'php-jenkins-hash', 'php-skein-hash', 'php-webdav', 'phpaudit', 'phpbench', 'pincaster', 'ping', 'posto', 'pub', 'public', 'public_keys', 'pure-ftpd', 'qscan', 'qtc', 'sharedance', 'skycache', 'sound', 'tmp', 'ucarp']
FTP_TLS class inherits from FTP, defining these additional methods and attributes:

ssl_version
The SSL version to use (defaults to ssl.PROTOCOL_SSLv23).

auth()
Set up a secure control connection by using TLS or SSL, depending on what is specified in the ssl_version attribute.

Changed in version 3.4: The method now supports hostname check with ssl.SSLContext.check_hostname and Server Name Indication (see ssl.HAS_SNI).

ccc()
Revert control channel back to plaintext. This can be useful to take advantage of firewalls that know how to handle NAT with non-secure FTP without opening fixed ports.

Added in version 3.3.

prot_p()
Set up secure data connection.

prot_c()
Set up clear text data connection.

Module variables
exception ftplib.error_reply
Exception raised when an unexpected reply is received from the server.

exception ftplib.error_temp
Exception raised when an error code signifying a temporary error (response codes in the range 400–499) is received.

exception ftplib.error_perm
Exception raised when an error code signifying a permanent error (response codes in the range 500–599) is received.

exception ftplib.error_proto
Exception raised when a reply is received from the server that does not fit the response specifications of the File Transfer Protocol, i.e. begin with a digit in the range 1–5.

ftplib.all_errors
The set of all exceptions (as a tuple) that methods of FTP instances may raise as a result of problems with the FTP connection (as opposed to programming errors made by the caller). This set includes the four exceptions listed above as well as OSError and EOFError."
"Python_firewall_rules_module","Module","Low","V1","Firewall, Rule, Python, Module, Rollback","def process_firewall_file(path: str) -> List[Dict[str, Any]]:
    results: List[Dict[str, Any]] = []

    with open(path, encoding=""utf-8"") as f:
        for raw in f:
            rule = parse_rule(raw)
            if not rule:
                continue

            rh = rule_hash(rule)

            # Already exists
            if firewall_rule_exists(rule[""name""], rule[""direction""]):
                results.append({
                    ""timestamp"": datetime.utcnow().isoformat(),
                    ""name"": rule[""name""],
                    ""direction"": rule[""direction""],
                    ""action"": rule[""action""],
                    ""targets"": rule[""targets""],
                    ""rule_hash"": rh,
                    ""status"": ""exists""
                })
                continue

            # Try to add
            if add_firewall_rule(rule):
                results.append({
                    ""timestamp"": datetime.utcnow().isoformat(),
                    ""name"": rule[""name""],
                    ""direction"": rule[""direction""],
                    ""action"": rule[""action""],
                    ""targets"": rule[""targets""],
                    ""rule_hash"": rh,
                    ""status"": ""added""
                })
            else:
                # Delete only the broken rule
                delete_firewall_rule(rule[""name""], rule[""direction""])
                results.append({
                    ""timestamp"": datetime.utcnow().isoformat(),
                    ""name"": rule[""name""],
                    ""direction"": rule[""direction""],
                    ""action"": rule[""action""],
                    ""targets"": rule[""targets""],
                    ""rule_hash"": rh,
                    ""status"": ""failed_and_removed""
                })

    return results
"
"Python_firewall_rule_Centurion_parcial","Script","Priority","V3","Python, Script, Firewall","# ======================================================
# MODULE 0 — Imports (Shared)
# ======================================================

import re
import ipaddress
import hashlib
import subprocess
import socket
import argparse
from datetime import datetime
from typing import Dict, Any, Optional, List, Tuple


# ======================================================
# MODULE 1 — Canonical Rule Library (Independent)
# ======================================================

CANONICAL_RULE_LIBRARY = """"""
# Google Analytics
action=block|name=CenturionCent_Block_GoogleAnalytics|direction=out|targets=216.58.0.0/16|protocol=any|profile=any|label:en=GoogleAnalyticsCIDR

# Google Fonts / Google APIs
action=block|name=CenturionCent_Block_GoogleFonts|direction=out|targets=142.250.0.0/15|protocol=any|profile=any|label:en=GoogleFonts

# Google Wide
action=block|name=CenturionCent_Block_GoogleWide|direction=out|targets=172.217.0.0/16|protocol=any|profile=any|label:en=GoogleWideCIDR

# Facebook
action=block|name=CenturionCent_Block_Facebook|direction=out|targets=157.240.0.0/16|protocol=any|profile=any|label:en=FacebookCIDR

# Twitter / X
action=block|name=CenturionCent_Block_Twitter|direction=out|targets=104.244.42.0/24|protocol=any|profile=any|label:en=TwitterCIDR

# Cloudflare
action=block|name=CenturionCent_Block_Cloudflare|direction=out|targets=104.16.0.0/12|protocol=any|profile=any|label:en=CloudflareCIDR

# Akamai
action=block|name=CenturionCent_Block_Akamai|direction=out|targets=23.0.0.0/11|protocol=any|profile=any|label:en=AkamaiCIDR

# AWS
action=block|name=CenturionCent_Block_AWS|direction=out|targets=52.95.0.0/16|protocol=any|profile=any|label:en=AWSCIDR

# Microsoft Telemetry
action=block|name=CenturionCent_Block_MicrosoftTelemetry|direction=out|targets=13.107.0.0/16|protocol=any|profile=any|label:en=MicrosoftTelemetryCIDR

# Generic Ads
action=block|name=CenturionCent_Block_GenericAds|direction=out|targets=198.51.100.0/24|protocol=any|profile=any|label:en=GenericAdsCIDR
"""""".strip()


# ======================================================
# MODULE 2 — Parsing + Hash + Linter (Independent)
# ======================================================

RULE_V1_RE = re.compile(r""^([^|]+)\|(in|out)\|(.+)$"", re.IGNORECASE)

def rule_hash(rule: dict) -> str:
    payload = ""|"".join([
        rule.get(""name"", """"),
        rule.get(""action"", """"),
        rule.get(""direction"", """"),
        rule.get(""targets"", """"),
        rule.get(""protocol"", """"),
        rule.get(""port"") or rule.get(""ports"", """"),
        rule.get(""profile"", """")
    ])
    return hashlib.sha256(payload.encode()).hexdigest()

def parse_rule(line: str) -> Optional[Dict[str, Any]]:
    line = line.strip()
    if not line or line.startswith(""#""):
        return None

    if ""action="" in line:
        data: Dict[str, Any] = {}
        for seg in line.split(""|""):
            seg = seg.strip()
            if ""="" in seg:
                k, v = seg.split(""="", 1)
                data[k.strip().lower()] = v.strip()

        if not all(k in data for k in (""action"", ""name"", ""direction"", ""targets"")):
            return None

        data[""protocol""] = data.get(""protocol"", ""any"")
        data[""profile""] = data.get(""profile"", ""any"")
        data[""targets""] = "","".join(
            t.strip() for t in data[""targets""].split("","") if t.strip()
        )
        data[""raw_line""] = line
        return data

    m = RULE_V1_RE.match(line)
    if not m:
        return None

    name, direction, ips = m.groups()
    ips = "","".join(i.strip() for i in ips.split("","") if i.strip())
    if not ips:
        return None

    return {
        ""action"": ""block"",
        ""name"": name,
        ""direction"": direction.lower(),
        ""targets"": ips,
        ""protocol"": ""any"",
        ""profile"": ""any"",
        ""raw_line"": line
    }

def lint_firewall_file(path: str) -> Dict[str, Any]:
    issues: List[Dict[str, Any]] = []
    seen_hashes: Dict[str, int] = {}
    seen_namedir: Dict[Tuple[str, str], int] = {}

    with open(path, encoding=""utf-8"") as f:
        lines = f.readlines()

    for idx, raw in enumerate(lines, start=1):
        stripped = raw.strip()
        if not stripped or stripped.startswith(""#""):
            continue

        rule = parse_rule(raw)
        if not rule:
            issues.append({
                ""line"": idx,
                ""raw"": raw.rstrip(""\n""),
                ""severity"": ""error"",
                ""code"": ""PARSE_FAILED"",
                ""detail"": ""Unable to parse rule line.""
            })
            continue

        for key in (""action"", ""name"", ""direction"", ""targets"", ""protocol"", ""profile""):
            if key not in rule or not str(rule[key]).strip():
                issues.append({
                    ""line"": idx,
                    ""raw"": raw.rstrip(""\n""),
                    ""severity"": ""error"",
                    ""code"": ""MISSING_FIELD"",
                    ""detail"": f""Missing required field '{key}'.""
                })

        action = rule[""action""].lower()
        if action not in {""block"", ""allow""}:
            issues.append({
                ""line"": idx,
                ""raw"": raw.rstrip(""\n""),
                ""severity"": ""error"",
                ""code"": ""INVALID_ACTION"",
                ""detail"": f""Invalid action '{rule['action']}'.""
            })

        direction = rule[""direction""].lower()
        if direction not in {""in"", ""out""}:
            issues.append({
                ""line"": idx,
                ""raw"": raw.rstrip(""\n""),
                ""severity"": ""error"",
                ""code"": ""INVALID_DIRECTION"",
                ""detail"": f""Invalid direction '{rule['direction']}'.""
            })

        for t in rule[""targets""].split("",""):
            t = t.strip()
            if not t:
                continue
            try:
                if ""/"" in t:
                    ipaddress.ip_network(t, strict=False)
                else:
                    ipaddress.ip_address(t)
            except ValueError:
                issues.append({
                    ""line"": idx,
                    ""raw"": raw.rstrip(""\n""),
                    ""severity"": ""error"",
                    ""code"": ""INVALID_TARGET"",
                    ""detail"": f""Invalid IP/CIDR target '{t}'.""
                })

        h = rule_hash(rule)
        if h in seen_hashes:
            issues.append({
                ""line"": idx,
                ""raw"": raw.rstrip(""\n""),
                ""severity"": ""warning"",
                ""code"": ""DUPLICATE_HASH"",
                ""detail"": f""Duplicate of line {seen_hashes[h]}.""
            })
        else:
            seen_hashes[h] = idx

        nd = (rule[""name""], rule[""direction""])
        if nd in seen_namedir:
            issues.append({
                ""line"": idx,
                ""raw"": raw.rstrip(""\n""),
                ""severity"": ""warning"",
                ""code"": ""DUPLICATE_NAME_DIRECTION"",
                ""detail"": f""Duplicate name+direction of line {seen_namedir[nd]}.""
            })
        else:
            seen_namedir[nd] = idx

    return {
        ""timestamp"": datetime.utcnow().isoformat(),
        ""file"": path,
        ""issues"": issues
    }


# ======================================================
# MODULE 3 — Formatter (Independent)
# ======================================================

def format_rule_line(rule: Dict[str, Any]) -> str:
    base_order = [""action"", ""name"", ""direction"", ""targets"", ""protocol"", ""profile""]

    rule = dict(rule)
    rule[""protocol""] = rule.get(""protocol"", ""any"")
    rule[""profile""] = rule.get(""profile"", ""any"")

    segments = [f""{key}={rule[key]}"" for key in base_order]

    extra_keys: List[str] = []
    raw = rule.get(""raw_line"", """")
    if raw and ""action="" in raw:
        for seg in raw.split(""|""):
            seg = seg.strip()
            if ""="" in seg:
                k, v = seg.split(""="", 1)
                if k.strip().lower() not in base_order:
                    extra_keys.append(f""{k.strip()}={v.strip()}"")

    return ""|"".join(segments + extra_keys)

def format_firewall_file(path_in: str, path_out: Optional[str] = None) -> Dict[str, Any]:
    if path_out is None:
        path_out = path_in

    with open(path_in, encoding=""utf-8"") as f:
        lines = f.readlines()

    formatted_lines: List[str] = []
    changed = False

    for raw in lines:
        stripped = raw.strip()
        if not stripped or stripped.startswith(""#""):
            formatted_lines.append(raw.rstrip(""\n""))
            continue

        rule = parse_rule(raw)
        if not rule:
            formatted_lines.append(raw.rstrip(""\n""))
            continue

        new_line = format_rule_line(rule)
        if new_line != stripped:
            changed = True

        formatted_lines.append(new_line)

    with open(path_out, ""w"", encoding=""utf-8"") as f:
        for line in formatted_lines:
            f.write(line + ""\n"")

    return {
        ""timestamp"": datetime.utcnow().isoformat(),
        ""file_in"": path_in,
        ""file_out"": path_out,
        ""changed"": changed
    }


# ======================================================
# MODULE 4 — System Snapshot (Independent)
# ======================================================

def system_snapshot() -> Dict[str, Any]:
    return {
        ""timestamp"": datetime.utcnow().isoformat(),
        ""firewall_rules"": subprocess.getoutput(""netsh advfirewall firewall show rule name=all""),
        ""active_connections"": subprocess.getoutput(""netstat -ano""),
        ""routing_table"": subprocess.getoutput(""route print""),
        ""ipconfig"": subprocess.getoutput(""ipconfig /all"")
    }


# ======================================================
# MODULE 5 — Firewall Executor (Independent, no duplicates)
# ======================================================

def firewall_rule_exists(name: str, direction: str) -> bool:
    r = subprocess.run(
        [""netsh"", ""advfirewall"", ""firewall"", ""show"", ""rule"", f""name={name}"", f""dir={direction}""],
        stdout=subprocess.DEVNULL,
        stderr=subprocess.DEVNULL,
        text=True
    )
    return r.returncode == 0

def add_firewall_rule(rule: Dict[str, Any]) -> bool:
    if firewall_rule_exists(rule[""name""], rule[""direction""]):
        return True
    cmd = [
        ""netsh"", ""advfirewall"", ""firewall"", ""add"", ""rule"",
        f""name={rule['name']}"",
        f""dir={rule['direction']}"",
        f""action={rule['action']}"",
        f""remoteip={rule['targets']}"",
        f""profile={rule['profile']}"",
        ""enable=yes""
    ]
    r = subprocess.run(
        cmd,
        stdout=subprocess.DEVNULL,
        stderr=subprocess.DEVNULL,
        text=True
    )
    return r.returncode == 0

def delete_firewall_rule(name: str, direction: str) -> None:
    subprocess.run(
        [""netsh"", ""advfirewall"", ""firewall"", ""delete"", ""rule"",
         f""name={name}"", f""dir={direction}""],
        stdout=subprocess.DEVNULL,
        stderr=subprocess.DEVNULL,
        text=True
    )

def process_firewall_file(path: str) -> List[Dict[str, Any]]:
    results: List[Dict[str, Any]] = []
    added: List[Tuple[str, str]] = []

    with open(path, encoding=""utf-8"") as f:
        for raw in f:
            rule = parse_rule(raw)
            if not rule:
                continue

            rh = rule_hash(rule)

            if firewall_rule_exists(rule[""name""], rule[""direction""]):
                status = ""exists""
            else:
                if not add_firewall_rule(rule):
                    for n, d in added:
                        delete_firewall_rule(n, d)
                    results.append({
                        ""timestamp"": datetime.utcnow().isoformat(),
                        ""name"": rule[""name""],
                        ""direction"": rule[""direction""],
                        ""action"": rule[""action""],
                        ""targets"": rule[""targets""],
                        ""rule_hash"": rh,
                        ""status"": ""rollback""
                    })
                    return results
                added.append((rule[""name""], rule[""direction""]))
                status = ""added""

            results.append({
                ""timestamp"": datetime.utcnow().isoformat(),
                ""name"": rule[""name""],
                ""direction"": rule[""direction""],
                ""action"": rule[""action""],
                ""targets"": rule[""targets""],
                ""rule_hash"": rh,
                ""status"": status
            })

    return results


# ======================================================
# MODULE 6 — Rule Builder CLI (Independent, no duplicates)
# ======================================================

def load_existing_rules(path: str) -> List[Dict[str, Any]]:
    rules: List[Dict[str, Any]] = []
    try:
        with open(path, encoding=""utf-8"") as f:
            for raw in f:
                r = parse_rule(raw)
                if r:
                    rules.append(r)
    except FileNotFoundError:
        pass
    return rules

def rule_exists_in_file(path: str, name: str, direction: str, targets: str) -> bool:
    rules = load_existing_rules(path)
    for r in rules:
        if r[""name""] == name and r[""direction""] == direction and r[""targets""] == targets:
            return True
    return False

def build_rule_line(name: str,
                    action: str,
                    direction: str,
                    targets: str,
                    protocol: str = ""any"",
                    profile: str = ""any"",
                    label_en: Optional[str] = None) -> str:
    segments = [
        f""action={action}"",
        f""name={name}"",
        f""direction={direction}"",
        f""targets={targets}"",
        f""protocol={protocol}"",
        f""profile={profile}"",
    ]
    if label_en:
        segments.append(f""label:en={label_en}"")
    return ""|"".join(segments)

def cli_rule_builder():
    parser = argparse.ArgumentParser(description=""Centurion Rule Builder CLI"")
    parser.add_argument(""--file"", required=True, help=""Firewall rules file path"")
    parser.add_argument(""--name"", required=True, help=""Rule name"")
    parser.add_argument(""--action"", default=""block"", choices=[""block"", ""allow""], help=""Rule action"")
    parser.add_argument(""--direction"", default=""out"", choices=[""in"", ""out""], help=""Rule direction"")
    parser.add_argument(""--targets"", required=True, help=""IP or CIDR or comma-separated list"")
    parser.add_argument(""--protocol"", default=""any"", help=""Protocol"")
    parser.add_argument(""--profile"", default=""any"", help=""Firewall profile"")
    parser.add_argument(""--label-en"", default=None, help=""English label"")
    args = parser.parse_args()

    targets_norm = "","".join(t.strip() for t in args.targets.split("","") if t.strip())

    if rule_exists_in_file(args.file, args.name, args.direction, targets_norm):
        return

    line = build_rule_line(
        name=args.name,
        action=args.action,
        direction=args.direction,
        targets=targets_norm,
        protocol=args.protocol,
        profile=args.profile,
        label_en=args.label_en
    )

    with open(args.file, ""a"", encoding=""utf-8"") as f:
        f.write(line + ""\n"")


# ======================================================
# MODULE 7 — Rule Auto‑Generator from Domains (Independent, no duplicates)
# ======================================================

def resolve_domain_ips(domain: str) -> List[str]:
    ips: List[str] = []
    try:
        info = socket.getaddrinfo(domain, None)
        for family, _, _, _, sockaddr in info:
            ip = sockaddr[0]
            if ip not in ips:
                ips.append(ip)
    except socket.gaierror:
        pass
    return ips

def generate_rules_for_domain(domain: str,
                              base_name: str,
                              direction: str = ""out"",
                              action: str = ""block"",
                              profile: str = ""any"",
                              protocol: str = ""any"") -> List[str]:
    ips = resolve_domain_ips(domain)
    if not ips:
        return []

    rules: List[str] = []
    for idx, ip in enumerate(ips, start=1):
        try:
            ipaddress.ip_address(ip)
        except ValueError:
            continue
        name = f""{base_name}_{idx}""
        targets = ip
        label_en = f""{domain}_{ip}""
        line = build_rule_line(
            name=name,
            action=action,
            direction=direction,
            targets=targets,
            protocol=protocol,
            profile=profile,
            label_en=label_en
        )
        rules.append(line)
    return rules

def append_domain_rules_to_file(domain: str, base_name: str, path: str) -> List[str]:
    existing = load_existing_rules(path)
    existing_set = {(r[""name""], r[""direction""], r[""targets""]) for r in existing}

    generated = generate_rules_for_domain(domain, base_name)
    appended: List[str] = []

    with open(path, ""a"", encoding=""utf-8"") as f:
        for line in generated:
            r = parse_rule(line)
            if not r:
                continue
            key = (r[""name""], r[""direction""], r[""targets""])
            if key in existing_set:
                continue
            existing_set.add(key)
            f.write(line + ""\n"")
            appended.append(line)

    return appended


# ======================================================
# MODULE 8 — Default Inbound Block Policy (Independent)
# ======================================================

def set_default_inbound_block() -> Dict[str, Any]:
    profiles = [""domainprofile"", ""privateprofile"", ""publicprofile""]
    results: List[Dict[str, Any]] = []

    for prof in profiles:
        cmd = [
            ""netsh"", ""advfirewall"", ""set"", prof,
            ""firewallpolicy"", ""blockinbound,allowoutbound""
        ]
        r = subprocess.run(
            cmd,
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL,
            text=True
        )
        results.append({
            ""profile"": prof,
            ""returncode"": r.returncode
        })

    return {
        ""timestamp"": datetime.utcnow().isoformat(),
        ""policy"": ""blockinbound,allowoutbound"",
        ""results"": results
    }"
"Python_Domain_to_Rule_Generator","Module","High ","V1","Python, Firewall, Module","# ======================================================
# MODULE  — Domain‑to‑Rule Generator (Dual Logging)
# ======================================================

GENERAL_LOG = ""centurion_domain_general.log""
EXCEPTION_LOG = ""centurion_domain_exceptions.log""


def log_general(entry: Dict[str, Any]):
    """"""Log every action, always.""""""
    entry[""log_type""] = ""general""
    with open(GENERAL_LOG, ""a"", encoding=""utf-8"") as lf:
        lf.write(f""{entry}\n"")


def log_exception(entry: Dict[str, Any]):
    """"""Log only errors, mismatches, anomalies.""""""
    entry[""log_type""] = ""exception""
    with open(EXCEPTION_LOG, ""a"", encoding=""utf-8"") as lf:
        lf.write(f""{entry}\n"")


def resolve_domain_ips(domain: str) -> List[str]:
    ips: List[str] = []
    try:
        info = socket.getaddrinfo(domain, None)
        for family, _, _, _, sockaddr in info:
            ip = sockaddr[0]
            if ip not in ips:
                ips.append(ip)
    except socket.gaierror:
        # DNS resolution failed
        log_exception({
            ""timestamp"": datetime.utcnow().isoformat(),
            ""domain"": domain,
            ""status"": ""dns_resolution_failed""
        })
    return ips


def generate_rules_for_domain(domain: str,
                              base_name: str,
                              direction: str = ""out"",
                              action: str = ""block"",
                              profile: str = ""any"",
                              protocol: str = ""any"") -> List[str]:

    timestamp = datetime.utcnow().isoformat()
    ips = resolve_domain_ips(domain)

    # CASE 1 — Domain resolved normally
    if ips:
        rules: List[str] = []
        for idx, ip in enumerate(ips, start=1):

            # Validate IP
            try:
                ipaddress.ip_address(ip)
            except ValueError:
                log_exception({
                    ""timestamp"": timestamp,
                    ""domain"": domain,
                    ""ip"": ip,
                    ""status"": ""invalid_ip_format""
                })
                continue

            name = f""{base_name}_{idx}""
            label_en = f""{domain}_{ip}""

            line = build_rule_line(
                name=name,
                action=action,
                direction=direction,
                targets=ip,
                protocol=protocol,
                profile=profile,
                label_en=label_en
            )

            rules.append(line)

            log_general({
                ""timestamp"": timestamp,
                ""domain"": domain,
                ""ip"": ip,
                ""rule_name"": name,
                ""status"": ""rule_generated""
            })

        return rules

    # CASE 2 — Domain did NOT resolve → create fallback block rule
    fallback_name = f""{base_name}_UNRESOLVED""
    fallback_label = f""{domain}_UNRESOLVED""

    fallback_rule = build_rule_line(
        name=fallback_name,
        action=""block"",
        direction=direction,
        targets=""0.0.0.0"",
        protocol=protocol,
        profile=profile,
        label_en=fallback_label
    )

    log_exception({
        ""timestamp"": timestamp,
        ""domain"": domain,
        ""status"": ""domain_unresolved_fallback_rule_created"",
        ""rule_name"": fallback_name
    })

    log_general({
        ""timestamp"": timestamp,
        ""domain"": domain,
        ""status"": ""fallback_rule_generated"",
        ""rule_name"": fallback_name
    })

    return [fallback_rule]


def append_domain_rules_to_file(domain: str,
                                base_name: str,
                                path: str) -> List[str]:

    timestamp = datetime.utcnow().isoformat()
    existing = load_existing_rules(path)
    existing_set = {(r[""name""], r[""direction""], r[""targets""]) for r in existing}

    generated = generate_rules_for_domain(domain, base_name)
    appended: List[str] = []

    with open(path, ""a"", encoding=""utf-8"") as f:
        for line in generated:
            r = parse_rule(line)
            if not r:
                log_exception({
                    ""timestamp"": timestamp,
                    ""domain"": domain,
                    ""line"": line,
                    ""status"": ""parse_failed""
                })
                continue

            key = (r[""name""], r[""direction""], r[""targets""])
            if key in existing_set:
                log_general({
                    ""timestamp"": timestamp,
                    ""domain"": domain,
                    ""rule_name"": r[""name""],
                    ""status"": ""duplicate_skipped""
                })
                continue

            existing_set.add(key)
            f.write(line + ""\n"")
            appended.append(line)

            log_general({
                ""timestamp"": timestamp,
                ""domain"": domain,
                ""rule_name"": r[""name""],
                ""status"": ""rule_appended""
            })

    return appended"
"Python_Domain_to_Rule_Generator","Module","High","V2","Python, Module"," ======================================================
# MODULE 7 — Rule Auto‑Generator from Domains (Independent, no duplicates)
# ======================================================


import socket
import ipaddress
from typing import Dict, Any, Optional, List


def resolve_domain_ips(domain: str) -> List[str]:
    ips: List[str] = []
    try:
        info = socket.getaddrinfo(domain, None)
        for family, _, _, _, sockaddr in info:
            ip = sockaddr[0]
            if ip not in ips:
                ips.append(ip)
    except socket.gaierror:
        pass
    return ips

def generate_rules_for_domain(domain: str,
                              base_name: str,
                              direction: str = ""out"",
                              action: str = ""block"",
                              profile: str = ""any"",
                              protocol: str = ""any"") -> List[str]:
    ips = resolve_domain_ips(domain)
    if not ips:
        return []

    rules: List[str] = []
    for idx, ip in enumerate(ips, start=1):
        try:
            ipaddress.ip_address(ip)
        except ValueError:
            continue
        name = f""{base_name}_{idx}""
        targets = ip
        label_en = f""{domain}_{ip}""
        line = build_rule_line(
            name=name,
            action=action,
            direction=direction,
            targets=targets,
            protocol=protocol,
            profile=profile,
            label_en=label_en
        )
        rules.append(line)
    return rules

def append_domain_rules_to_file(domain: str, base_name: str, path: str) -> List[str]:
    existing = load_existing_rules(path)
    existing_set = {(r[""name""], r[""direction""], r[""targets""]) for r in existing}

    generated = generate_rules_for_domain(domain, base_name)
    appended: List[str] = []

    with open(path, ""a"", encoding=""utf-8"") as f:
        for line in generated:
            r = parse_rule(line)
            if not r:
                continue
            key = (r[""name""], r[""direction""], r[""targets""])
            if key in existing_set:
                continue
            existing_set.add(key)
            f.write(line + ""\n"")
            appended.append(line)

    return appended
"
,,"Low","V1",,
